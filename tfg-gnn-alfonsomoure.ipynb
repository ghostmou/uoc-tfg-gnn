{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición, tipologías y casos de uso de Graph Neural Networks para el aprendizaje basado en relaciones: presentación de implementación\n",
    "\n",
    "## Introducción al notebook\n",
    "\n",
    "Este documento de tipo notebook acompaña a la memoria del TFG con título *Definición, tipologías y casos de uso de Graph Neural Networks para el aprendizaje basado en relaciones*. El objetivo del documento es presentar la implementación de las pruebas realizadas con diferentes modelos de redes neuronales gráficas explicadas en el proyecto, así como plantear distintas aproximaciones para su codificación.\n",
    "\n",
    "Aunque van a explicarse algunos conceptos relacionados con las librerías de Python utilizadas, se deja en manos de la memoria de proyecto el explicar la base teórica de los mismos, así como la evaluación e interpretación de los resultados obtenidos.\n",
    "\n",
    "## Estructura del documento\n",
    "\n",
    "Mediante el uso del orden presentado en la memoria, se van a repasar distintas aproximaciones a las GNN con dos planteamientos principales:\n",
    "\n",
    "1. Clasificación de nodos dentro de un grafo:\n",
    "    1. Implementación mediante un modelo con base espectral.\n",
    "    1. Implementación con un modelo espacial mediante paso de mensajes.\n",
    "    1. Contraste de resultados frente a un modelo tradicional que no tiene en cuenta la estructura de los datos, en busca de justificar la motivación de la existencia de las redes gráficas.\n",
    "1. Predicción de enlazado.\n",
    "    1. Implementación de un modelo que hace uso de paso de mensajes para predecir enlaces entre nodos.\n",
    "\n",
    "Para cada uno de estos ejemplos se presentarán resultados de métricas de precisión durante el proceso de entrenamiento, para lo que se hará uso de datos de validación, así como pruebas finales sobre datos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno\n",
    "\n",
    "### Instalación de módulos\n",
    "\n",
    "Como primer paso, se procede a instalar los módulos necesarios:\n",
    "\n",
    "* [numpy](https://numpy.org/), para poder realizar las operaciones necesarias sobre los datos.\n",
    "* [TensorFlow](https://www.tensorflow.org/), como librería principal para ejecutar los algoritmos de aprendizaje computacional del bloque de clasificación de nodos.\n",
    "* [Spektral](https://graphneural.network/), una cómoda librería y colección de sets de datos que facilita el trabajo con redes neuronales gráficas.\n",
    "* [PyTorch](https://pytorch.org/), librería de aprendizaje computacional que será usada para las pruebas de predicción de enlaces. Junto a ella se instalarán también algunas sublibrerías que serán necesarias.\n",
    "* [tqdm](https://github.com/tqdm/tqdm), una librería simple para crear barras de progreso, con el simple objetivo de facilitar la lectura de algunas pruebas.\n",
    "\n",
    "A continuación, se hacen las llamadas oportunas para instalar las mismas en el entorno actual. De manera adicional, se adjunta el fichero `requirements.txt` junto con este notebook para su uso en caso de necesidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.19.5)\n",
      "Requirement already satisfied: tensorflow in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: spektral in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: joblib in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.1.0)\n",
      "Requirement already satisfied: networkx in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.6.3)\n",
      "Requirement already satisfied: lxml in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (4.6.4)\n",
      "Requirement already satisfied: scipy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.7.2)\n",
      "Requirement already satisfied: pandas in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.3.4)\n",
      "Requirement already satisfied: tqdm in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (4.62.3)\n",
      "Requirement already satisfied: requests in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.26.0)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.0.1)\n",
      "Requirement already satisfied: numpy<1.20 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.19.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.42.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.37.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (4.0.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.13.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.19.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (12.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.22.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->spektral) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->spektral) (2021.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scikit-learn->spektral) (3.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (57.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.1.1)\n",
      "Requirement already satisfied: torch in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch) (4.0.0)\n",
      "Requirement already satisfied: torch-cluster in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.5.9)\n",
      "Requirement already satisfied: torch-scatter in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (2.0.9)\n",
      "Requirement already satisfied: torch-sparse in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (0.6.12)\n",
      "Requirement already satisfied: scipy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-sparse) (1.7.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scipy->torch-sparse) (1.19.5)\n",
      "Requirement already satisfied: torch-geometric in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: PyYAML in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (6.0)\n",
      "Requirement already satisfied: requests in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: rdflib in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (4.62.3)\n",
      "Requirement already satisfied: googledrivedownloader in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (0.4)\n",
      "Requirement already satisfied: pyparsing in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (3.0.6)\n",
      "Requirement already satisfied: networkx in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (2.6.3)\n",
      "Requirement already satisfied: pandas in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (1.0.1)\n",
      "Requirement already satisfied: scipy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (1.7.2)\n",
      "Requirement already satisfied: yacs in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (0.1.8)\n",
      "Requirement already satisfied: numpy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (1.19.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->torch-geometric) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->torch-geometric) (2.8.2)\n",
      "Requirement already satisfied: isodate in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from rdflib->torch-geometric) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from rdflib->torch-geometric) (57.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->torch-geometric) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->torch-geometric) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->torch-geometric) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->torch-geometric) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (4.62.3)\n"
     ]
    }
   ],
   "source": [
    "# Install required modules\n",
    "necessary_modules = ['numpy', 'tensorflow', 'spektral', 'torch', 'torch-cluster', 'torch-scatter', 'torch-sparse', 'torch-geometric', 'tqdm']\n",
    "for module in necessary_modules:\n",
    "    !pip install {module}\n",
    "\n",
    "# Import numpy module, that is going to be use across the project\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de TensorBoard\n",
    "\n",
    "Tanto en los ejemplos donde se hace uso de TensorFlow como en aquellos implementados con PyTorch, se extraerán las métricas de aprendizaje y precisión a ficheros de registro que podrán ser leídos mediante [TensorBoard](https://www.tensorflow.org/tensorboard?hl=en), un entorno del propio TensorFlow que facilita su seguimiento y visualización. \n",
    "\n",
    "Para ello, es preciso preparar un directorio donde guardar el historial de registro de mensajes y configurar el propio entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorBoard callback to be able to use it in all the code samples\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Prepare placement for the logs\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "# Create directory if it doesn't exists\n",
    "from pathlib import Path\n",
    "Path(root_logdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define a function that returns the path to store the log depending on the experiment\n",
    "def get_run_logdir(experiment_name):\n",
    "    import time\n",
    "    run_id = time.strftime(f'run_{experiment_name}_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de pruebas\n",
    "\n",
    "A continuación se presentan las distintas pruebas realizadas.\n",
    "\n",
    "### Pruebas de clasificación de nodos\n",
    "\n",
    "Tal como se expone en la memoria de proyecto, las redes neuronales gráficas permiten, entre otras cosas, la clasificación de nodos en base a la información de sus vecindarios, lo que permite asignar clases dentro del contexto de las entidades de un grafo.\n",
    "\n",
    "Para la realización de estas pruebas se hará uso de la librería Spektral, que ya ha sido instalada con anterioridad. Spektral ofrece una amplia colección de modelos de red neuronal gráfica ya implementados, así como distintas utilidades de código para su explotación. A modo de añadido, también incorpora una clase especial para poder cargar juegos de datos con distintas características, entre los que se encuentra CORA, que ha sido escogido para la realización de estas pruebas.\n",
    "\n",
    "Así, el primer paso será importar el juego de datos y repasarlo, para lo que será preciso cargar la propia librería Spektral, así como TensorFlow y Keras, que pasan a sumarse a numpy, ya cargado, a la lista de módulos utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary librearies and define aliases to refer to them easier\n",
    "import spektral\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga y preparación del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se indica en la memoria de proyecto, se hará uso del juego de datos conocido como CORA. Gracias a Spektral, es sencillo descargar este juego de datos y sus distintas estructuras ya preparadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# Download CORA dataset and its different members\n",
    "dataset = spektral.datasets.citation.Citation(\n",
    "    'cora', \n",
    "    random_split=False, # split randomly: 20 nodes per class for training, 30 nodes \n",
    "        # per class for validation; or \"Planetoid\" (Yang et al. 2016)\n",
    "    normalize_x=False,  # normalize the features\n",
    "    dtype=np.float32 # numpy data type for the graph data\n",
    "    )\n",
    "\n",
    "# Also load a list of labels as names, justo to be able to use it\n",
    "label_names = ['Case_Based', 'Genetic_Algorithms', 'Neural_Networks', \n",
    "    'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto, se pueden consultar las características del conjunto de datos que ha sido descargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Citation(n_graphs=1)\n",
      "First graph: Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)\n",
      "Node labels: Case_Based, Genetic_Algorithms, Neural_Networks, Probabilistic_Methods, Reinforcement_Learning, Rule_Learning, Theory\n",
      "Training samples: 140\n",
      "Validation samples: 500\n",
      "Test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}')\n",
    "print('First graph: {}'.format(dataset.graphs[0]))\n",
    "print('Node labels: {}'.format(', '.join(label_names)))\n",
    "print(f'Training samples: {np.sum(dataset.mask_tr)}')\n",
    "print(f'Validation samples: {np.sum(dataset.mask_va)}')\n",
    "print(f'Test samples: {np.sum(dataset.mask_te)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a los datos extraídos, se puede ver que la variable `dataset` contiene un grafo, el cuál puede ser accedido para conocer sus características. De este modo, se comprueba que el conjunto de datos CORA ha sido descargado y está compuesto por:\n",
    "\n",
    "* 2708 nodos o vértices, que conforman el grafo.\n",
    "* 1433 atributos de nodo.\n",
    "* 0 atributos de relación, es decir, los enlaces que relacionan los nodos no contienen información. Como se explica en la memoria de proyecto, esto impide tener distintas categorías en los vínculos y limitará el aprendizaje al contenido de los nodos y el contexto con el que se relacionan.\n",
    "* 7 clases. En base a la definición del juego de datos, se sabe que los vértices se clasifican en dicho número de grupos. Sin embargo, como se explica en la memoria de proyecto, también es posible hacer uso de GNNs para clasificar grafos, por lo que Spektral nos permite trabajar con dos tipos de etiquetas: de nodo y de grafo.\n",
    "\n",
    "Además, Spektral se encarga de generar los subconjuntos del juego de datos que son necesarios para las pruebas a realizar, que quedan divididos en tres:\n",
    "\n",
    "* Conjunto de entrenamiento, que cuenta con 140 nodos. Es accesible desde `dataset.mask_tr`.\n",
    "* Conjunto de validación, compuesto por 500 vértices. Puede recuperarse mediante `dataset.mask_va`.\n",
    "* Conjunto de pruebas o *test*, formado por 1000 entidades. Se pueden computar desde `dataset.mask_te`.\n",
    "\n",
    "Esta separación en conjuntos de entrenamiento, validación y test se hace mediante un enmascaramiento: están formados por un vector de tipo `narray` con tantas posiciones como nodos hay en el conjunto de datos. En cada posición se registrará un `1` si el vértice correspondiente pertenece al conjunto y con un `0` en caso contrario.\n",
    "\n",
    "Por esta razón, se presenta la posibilidad de generar los pesos de cada vértice según si han sido seleccionados o no. Con el fin de fijar el mismo peso para todos dentro de cada conjunto, se procede a dividir cada uno de ellos por el número de observaciones en su grupo. El resultado es almacenado en `weighted_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples weights: 0.0071428571827709675\n",
      "Validation samples weights: 0.0020000000949949026\n",
      "Test samples weights: 0.0010000001639127731\n"
     ]
    }
   ],
   "source": [
    "weighted_mask = [\n",
    "    mask.astype(np.float32) / np.count_nonzero(mask)\n",
    "    for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te)\n",
    "]\n",
    "\n",
    "print(f'Training samples weights: {np.nanmean(np.where(weighted_mask[0] > 0, weighted_mask[0],np.nan), 0)}')\n",
    "print(f'Validation samples weights: {np.nanmean(np.where(weighted_mask[1] > 0, weighted_mask[1],np.nan), 0)}')\n",
    "print(f'Test samples weights: {np.nanmean(np.where(weighted_mask[2] > 0, weighted_mask[2],np.nan), 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del grafo registrado, es posible acceder a las diferentes estructuras que lo representan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características de los nodos, en formato matriz:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "Matriz de adyacencia, de tipo sparse matrix:\n",
      "  (0, 633)\t1.0\n",
      "  (0, 1862)\t1.0\n",
      "  (0, 2582)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 652)\t1.0\n",
      "  (1, 654)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 332)\t1.0\n",
      "  (2, 1454)\t1.0\n",
      "  (2, 1666)\t1.0\n",
      "  (2, 1986)\t1.0\n",
      "  (3, 2544)\t1.0\n",
      "  (4, 1016)\t1.0\n",
      "  (4, 1256)\t1.0\n",
      "  (4, 1761)\t1.0\n",
      "  (4, 2175)\t1.0\n",
      "  (4, 2176)\t1.0\n",
      "  (5, 1629)\t1.0\n",
      "  (5, 1659)\t1.0\n",
      "  (5, 2546)\t1.0\n",
      "  (6, 373)\t1.0\n",
      "  (6, 1042)\t1.0\n",
      "  (6, 1416)\t1.0\n",
      "  (6, 1602)\t1.0\n",
      "  (7, 208)\t1.0\n",
      "  :\t:\n",
      "  (2694, 431)\t1.0\n",
      "  (2694, 2695)\t1.0\n",
      "  (2695, 431)\t1.0\n",
      "  (2695, 2694)\t1.0\n",
      "  (2696, 2615)\t1.0\n",
      "  (2697, 986)\t1.0\n",
      "  (2698, 1400)\t1.0\n",
      "  (2698, 1573)\t1.0\n",
      "  (2699, 2630)\t1.0\n",
      "  (2700, 1151)\t1.0\n",
      "  (2701, 44)\t1.0\n",
      "  (2701, 2624)\t1.0\n",
      "  (2702, 186)\t1.0\n",
      "  (2702, 1536)\t1.0\n",
      "  (2703, 1298)\t1.0\n",
      "  (2704, 641)\t1.0\n",
      "  (2705, 287)\t1.0\n",
      "  (2706, 165)\t1.0\n",
      "  (2706, 169)\t1.0\n",
      "  (2706, 1473)\t1.0\n",
      "  (2706, 2707)\t1.0\n",
      "  (2707, 165)\t1.0\n",
      "  (2707, 598)\t1.0\n",
      "  (2707, 1473)\t1.0\n",
      "  (2707, 2706)\t1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Características de los nodos, en formato matriz:\\n{}\\n\\n'.format(dataset.graphs[0].x))\n",
    "print('Matriz de adyacencia, de tipo sparse matrix:\\n{}\\n\\n'.format(dataset.graphs[0].a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características de las aristas, en formato matriz (vacía, en este caso):\n",
      "None\n",
      "\n",
      "\n",
      "Etiquetas de cada nodo:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Características de las aristas, en formato matriz (vacía, en este caso):\\n{}\\n\\n'.format(dataset.graphs[0].e))\n",
    "print('Etiquetas de cada nodo:\\n{}'.format(dataset.graphs[0].y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 1: Implementación ConvGNN espectral\n",
    "\n",
    "Gracias al fichero de datos preparado, es posible probar la implementación de uno de los modelos presentados en la memoria de proyecto: una red neuronal convolucional gráfica o ConvGNN con una aproximación espectral.\n",
    "\n",
    "Como se explica en el documento de proyecto, el uso de la estructural espectral permite el aprendizaje y predicción en base a la estructura general del grafo, por lo que se hará uso de la matriz de adyacencia y las características de los nodos, pero sin la posibilidad de tener en cuenta la estructura general, algo que veremos en mayor detalle en la implementación de una ConvGNN espacial en el siguiente apartado.\n",
    "\n",
    "El primer paso será cargar los datos en un `Loader`, una clase dentro de Spektral que se encarga de gestionar el conjunto de datos y devolver los subconjuntos necesarios para el entrenamiento de la red neuronal. Así, se procede a crear uno para el conjunto de entrenamiento y otro para el de validación. Puesto que el ejemplo está destinado a aprender de una única representación de grafo, se usará un `SingleLoader` y se le pasarán los pesos de los nodos, con el fin de tenerlos en cuenta en la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data.loaders import SingleLoader\n",
    "loader_training = SingleLoader(dataset, sample_weights=weighted_mask[0])\n",
    "loader_validation = SingleLoader(dataset, sample_weights=weighted_mask[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante la fase de entrenamiento, cada loader devolverá una tupla compuesta por una tupla que contendrá los inputs del modelo, las etiquetas de cada nodo y los pesos de los mismos desde la estructura pasada como `sample_weights`.\n",
    "\n",
    "Con los datos listos para ser usados, el siguiente paso será crear el modelo desde Spektral. En este caso, se hará uso de la clase `GCN` de Spektral, la cuál hace uso de la arquitectura propuesta en el paper de Kipf y Welling de 2016 (**REFERENCIA** desde memoria). La instancia se crea mediante el paso de:\n",
    "\n",
    "1. Número de etiquetas de nodo mediante `n_labels`, dato que se recoge desde el conjunto de datos creado.\n",
    "1. Número de características de nodos mediante `n_input_channels`. Tal como se explica en la memoria, este modelo básico de red convolucional gráfica hace uso de las características de cada nodo y las relaciones de su entorno, pero no tiene en cuenta las propiedades de los enlaces entre vértices, por lo que estas son ignoradas como entrada.\n",
    "\n",
    "Además, se pueden destacar algunas propiedades adicionales:\n",
    "\n",
    "* Se fija un ritmo de aprendizaje de 0.01.\n",
    "* Se elige la función de suma como método de agregación.\n",
    "* Se utiliza el optimizador `Adam`.\n",
    "* Se opta por *cross entropy* como función de pérdida.\n",
    "* Se configura la métrica de precisión para su seguimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 12:34:29.182540: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from spektral.models.gcn import GCN # Import model\n",
    "from tensorflow.keras.optimizers import Adam # Import optimizers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy # Import loss function from Keras\n",
    "\n",
    "# Set initial configuration\n",
    "learning_rate = 0.01\n",
    "reduction_function = 'sum'\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_function = CategoricalCrossentropy(reduction=reduction_function)\n",
    "metrics_to_evaluate = ['acc']\n",
    "\n",
    "# Create model from Spektral\n",
    "model_gcn = GCN(n_labels=dataset.n_labels, n_input_channels=dataset.n_node_features)\n",
    "\n",
    "# Compile loaded model\n",
    "model_gcn.compile(\n",
    "    optimizer=optimizer, loss=loss_function, weighted_metrics=metrics_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo listo, es posible proceder a llevar a cabo su entrenamiento. Con el fin de detener el proceso tan pronto como se detecte que la precisión no progresa, se hace uso del callback `EartlyStopping` de Keras con una paciencia de `5`, lo que establece que el proceso se detendrá si pasado dicho número de épocas (*epochs*) no se detecta una mejora en los resultados. De igual manera, se establece un máximo de 50 épocas de entrenamiento.\n",
    "\n",
    "Para terminar, se añade un callback para enviar los resultados a TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5823 - acc: 0.1357 - val_loss: 2.4473 - val_acc: 0.2160\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1193 - acc: 0.2357 - val_loss: 1.9142 - val_acc: 0.3280\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9732 - acc: 0.3429 - val_loss: 1.6517 - val_acc: 0.4180\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7282 - acc: 0.4500 - val_loss: 1.6359 - val_acc: 0.3840\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6486 - acc: 0.4643 - val_loss: 1.6203 - val_acc: 0.3920\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4945 - acc: 0.5000 - val_loss: 1.6186 - val_acc: 0.3780\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4453 - acc: 0.5571 - val_loss: 1.6002 - val_acc: 0.3920\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3884 - acc: 0.4643 - val_loss: 1.5890 - val_acc: 0.4360\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3577 - acc: 0.5429 - val_loss: 1.5836 - val_acc: 0.4720\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2472 - acc: 0.6000 - val_loss: 1.5654 - val_acc: 0.5280\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2367 - acc: 0.5714 - val_loss: 1.5340 - val_acc: 0.5600\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1980 - acc: 0.6000 - val_loss: 1.4824 - val_acc: 0.6100\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0712 - acc: 0.6857 - val_loss: 1.4511 - val_acc: 0.6240\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1592 - acc: 0.6429 - val_loss: 1.4352 - val_acc: 0.6600\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0234 - acc: 0.6643 - val_loss: 1.4277 - val_acc: 0.6520\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0066 - acc: 0.6429 - val_loss: 1.4204 - val_acc: 0.6340\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9573 - acc: 0.6571 - val_loss: 1.4148 - val_acc: 0.6140\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8490 - acc: 0.7643 - val_loss: 1.4040 - val_acc: 0.6280\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8813 - acc: 0.7286 - val_loss: 1.3888 - val_acc: 0.6440\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8223 - acc: 0.7500 - val_loss: 1.3660 - val_acc: 0.6640\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6976 - acc: 0.7786 - val_loss: 1.3522 - val_acc: 0.6620\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7405 - acc: 0.7714 - val_loss: 1.3510 - val_acc: 0.6800\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6650 - acc: 0.7143 - val_loss: 1.3621 - val_acc: 0.6780\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6472 - acc: 0.7929 - val_loss: 1.3772 - val_acc: 0.6860\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7339 - acc: 0.7571 - val_loss: 1.3887 - val_acc: 0.6920\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6085 - acc: 0.8286 - val_loss: 1.4018 - val_acc: 0.6940\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6215 - acc: 0.7571 - val_loss: 1.4073 - val_acc: 0.6960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143af5eb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eartly stopping settings\n",
    "early_stopping_patience = 5\n",
    "max_number_of_epochs = 50\n",
    "\n",
    "# Fit the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model_gcn.fit(\n",
    "    loader_training.load(),\n",
    "    steps_per_epoch=loader_training.steps_per_epoch,\n",
    "    validation_data=loader_validation.load(),\n",
    "    validation_steps=loader_validation.steps_per_epoch,\n",
    "    epochs=max_number_of_epochs,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=early_stopping_patience,  restore_best_weights=True),\n",
    "        TensorBoard(get_run_logdir('gcn_spectral'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Añadir número de referencia desde memoria cuando esté todo listo\n",
    "# TODO Aclarar uso de Adam\n",
    "# TODO Probar con otros modelos mediante GridSearch (si nos da tiempo)\n",
    "\n",
    "# TODO Probar sobre conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 2 2: ConvGNN espacial mediante paso de mensajes: MPNN\n",
    "\n",
    "En el ejemplo anterior se ha basado el aprendizaje y la clasificación en la estructura espectral de los datos cargados, es decir, en la estructura de la matriz de adyacencia. Sin embargo, tal y como se explica en la memoria de proyecto, esta aproximación puede ser pobre para escenarios donde las relaciones (aristas) entre entidades (vértices) del grafo tienen un significado o importancia diferente, o cuando el contexto de un nodo, construido mediante los atributos de sus vecinos, es importante para la clasificación.\n",
    "\n",
    "Para poder preparar este ejemplo, se hará uso de la clase `MessagePassing` de Spektral, que ofrece una API ya preparada para configurar la función de activación y personalizar el comportamiento para distintos juegos de datos. Así, será preciso personalizar:\n",
    "\n",
    "* Función para la construcción del mensaje pasado entre dos vértices vía la arista que los une. Es conocida como `message` dentro de la API de Spektral.\n",
    "* Selección de la función de agregación de los mensajes pasados desde cada arista a cada nodo: suma, media, etc. Aparece definida como `aggregate`.\n",
    "\n",
    "Puesto que las GNN basadas en paso de mensajes requieren sucesivas iteraciones que permitan propagar los mensajes a niveles cada vez más lejanos, la función `propagate` lo ejecuta y computa los atributos de cada nodo tras pasar los mensajes de todas las aristas del grafo y computar la correspondiente función de agregación.\n",
    "\n",
    "Puesto que Spektral está construido sobre Keras, es preciso, además, implementar algunos de los métodos heredados de la clase `Layer` para definir la capa gráfica espacial:\n",
    "\n",
    "* `__init__`, donde se define la función de activación, se pasan el resto de hiperparámetros estándar y se guarda el dato del tamaño de la salida, que será usado más adelante.\n",
    "* `build`, cuya misión es la de inicializar los pesos de la capa mediante la llamada a `add_weight` y asignar el tamaño que tendrá la matriz utilizada para almacenar los pesos dentro de la capa. La matriz de pesos tendrá tantas filas como la entrada y columnas como la salida.\n",
    "* `call` es el método encargado de ejecutar los cálculos de la capa. Puesto que estamos hablando de paso de mensajes, la salida de la capa será función de las característica de los nodos de entrada y los pesos de la capa. Al final de la misma, en lugar de llamar a la función de activación, se llama a `propagate`, un método disponible dentro de `MessagePassing` encargado de realizar la propagación de los mensajes de cada nodo a sus vecinos.\n",
    "\n",
    "A estos métodos estándar, se incorporan otros de la propia API de Spektral, especializados en el trabajo con redes gráficas:\n",
    "\n",
    "* `message`, encargado de componer el mensaje que será pasado entre los nodos. En este ejemplo se hace uso de la información de los nodos vecinos, accesibles mediante `get_j`.\n",
    "* `aggregate`, con el cometido de definir la función de agregación para los mensajes del vecindario. Aquí se hace uso de la media de todos los mensajes del vecindario, aunque una posible mejora del modelo podría ser el uso de hiperparámetros para encontrar la que mejores reusltados pueda dar. Esta opción es posible desde el propio constructor.\n",
    "* `update` donde, ahora sí, se hace uso de la función de activaciónn apra actualizar la matriz de pesos.\n",
    "\n",
    "Con todo, se empieza creando la clase MPNNLayer como herencia `MessagePassing` para preparar la personalización de los citados métodos y definir la capa de paso de mensajes del modelo a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import MessagePassing\n",
    "\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, n_out, activation, **kwargs):\n",
    "        # Initialize message passing layer with the activation function chosen when creating the model\n",
    "        super().__init__(activation=activation, **kwargs)\n",
    "        self.n_out = n_out\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(batch_input_shape[0][-1], self.n_out)\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "\n",
    "        # Update node features based on inputs by multiplying node attributes by \n",
    "        # the weights stored during build.\n",
    "        # Kipf 2016\n",
    "        x = tf.matmul(x, self.kernel)\n",
    "\n",
    "        # Return propagation result\n",
    "        return self.propagate(x=x, a=a)\n",
    "\n",
    "    def message(self, x):\n",
    "        return self.get_j(x)\n",
    "    \n",
    "    def aggregate(self, messages): \n",
    "        # We need to return the result of applying the aggregate function over the messages\n",
    "\n",
    "        # Try to use the mean as aggregate function. We use a scatter mean method for this experiment:\n",
    "        return spektral.layers.ops.scatter_mean(messages, self.index_i, self.n_nodes)\n",
    "\n",
    "    def update(self, embeddings):\n",
    "        return self.activation(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creada la capa, podemos hacer uso de la misma creando un modelo mediante la API funcional de Keras. Para ello, se empieza por configurar algunos parámetros básicos para su funcionamiento:\n",
    "\n",
    "* Ratio de regularización (o *regularization rate*): con el fin de regularizar los contenidos. Se inicia con un valor de `5e-6`.\n",
    "* Ratio de aprendizaje (o *learning rate*) con un valor de 0.2.\n",
    "* Número de epochs de entrenamiento, que son fijadas en 20.\n",
    "* Nivel de paciencia para el early stopping que será usado más abajo en la etapa de entrenamiento.\n",
    "\n",
    "Hecho esto, se extran las características principales de los datos: número de nodos, número de careacterísticas por nodo y número de clases para clasificarlos. Estos datos serán usados para instanciar la capa de paso de mensajes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup for the model\n",
    "l2_regularization_rate = 5e-6\n",
    "learning_rate = 0.2\n",
    "epochs = 20\n",
    "patience = 10\n",
    "\n",
    "# Input parameters\n",
    "number_of_nodes = dataset.n_nodes\n",
    "number_of_node_features = dataset.n_node_features\n",
    "number_of_labels = dataset.n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de definir las entradas. Para ello, se crearán dos tensores:\n",
    "\n",
    "* `adjacency_matrix` con la matriz de adyacencia, que contendrá la matriz de adyacencia y que permitirá saber las conexiones de cada nodo.\n",
    "* `x_input` con las características de cada nodo.\n",
    "\n",
    "Ambas son usadas para definir la capa de salida del modelo, que será construida mediante la clase definida para el MPNNLayer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define input tensors\n",
    "# We define two input tensors: one for the nodes and one for the adjacency matrix\n",
    "from keras.layers import Input\n",
    "adjacency_input = Input(\n",
    "    (number_of_nodes,), sparse=True, dtype=dataset[0].a.dtype,\n",
    "    name='adjacency_matrix_input'\n",
    ")\n",
    "x_input = Input(\n",
    "    shape=(number_of_node_features,),\n",
    "    name='nodes_input'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output layer based on the MPNN layer defined previously as MPNNLayer\n",
    "mpnn_output_layer = MPNNLayer(\n",
    "    number_of_labels, activation=keras.activations.softmax,\n",
    "    kernel_regularizer=keras.regularizers.l2(l2_regularization_rate),\n",
    "    use_bias=False, name='mpnn_layer'\n",
    ")([x_input, adjacency_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mpnn_gcn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " nodes_input (InputLayer)       [(None, 1433)]       0           []                               \n",
      "                                                                                                  \n",
      " adjacency_matrix_input (InputL  [(None, 2708)]      0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " mpnn_layer (MPNNLayer)         (None, 7)            10031       ['nodes_input[0][0]',            \n",
      "                                                                  'adjacency_matrix_input[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,031\n",
      "Trainable params: 10,031\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile model\n",
    "from keras.models import Model\n",
    "model_mpnn = Model(\n",
    "    name='mpnn_gcn',\n",
    "    inputs=[x_input, adjacency_input],\n",
    "    outputs=mpnn_output_layer\n",
    ")\n",
    "model_mpnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    weighted_metrics=['acc']\n",
    ")\n",
    "model_mpnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 0.1002 - acc: 0.1643 - val_loss: 0.2232 - val_acc: 0.6240\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0153 - acc: 0.9857 - val_loss: 0.1666 - val_acc: 0.7000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0032 - acc: 0.9929 - val_loss: 0.1634 - val_acc: 0.7140\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1729 - val_acc: 0.7100\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7404e-04 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.7060\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4123e-04 - acc: 1.0000 - val_loss: 0.1980 - val_acc: 0.7100\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3434e-04 - acc: 1.0000 - val_loss: 0.2102 - val_acc: 0.7100\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.9853e-05 - acc: 1.0000 - val_loss: 0.2215 - val_acc: 0.7100\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.0061e-05 - acc: 1.0000 - val_loss: 0.2320 - val_acc: 0.7100\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2859e-05 - acc: 1.0000 - val_loss: 0.2416 - val_acc: 0.7100\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2460e-05 - acc: 1.0000 - val_loss: 0.2504 - val_acc: 0.7100\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5914e-05 - acc: 1.0000 - val_loss: 0.2584 - val_acc: 0.7080\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1647e-05 - acc: 1.0000 - val_loss: 0.2658 - val_acc: 0.7040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143aa8730>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "loader_tr = SingleLoader(dataset, sample_weights=dataset.mask_tr)\n",
    "loader_va = SingleLoader(dataset, sample_weights=dataset.mask_va)\n",
    "model_mpnn.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_va.load(),\n",
    "    validation_steps=loader_va.steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "        TensorBoard(get_run_logdir('gcn_spatial'))\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo, se puede evaluar contra el "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3277 - acc: 0.7330\n",
      "Test loss: 0.32770317792892456\n",
      "Test accuracy: 0.7329999804496765\n"
     ]
    }
   ],
   "source": [
    "loader_te = SingleLoader(dataset, sample_weights=dataset.mask_te)\n",
    "results = model_mpnn.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "\n",
    "print(f'Test loss: {results[0]}')\n",
    "print(f'Test accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0080289cbe72122e4cc1d387721a77267b793dcb0222027115d0fe70e838b1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('uoc-tfg-gnn': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
