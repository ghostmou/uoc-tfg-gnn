{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición, tipologías y casos de uso de Graph Neural Networks para el aprendizaje basado en relaciones: presentación de implementación\n",
    "\n",
    "## Introducción al notebook\n",
    "\n",
    "Este documento de tipo notebook acompaña a la memoria del TFG con título *Definición, tipologías y casos de uso de Graph Neural Networks para el aprendizaje basado en relaciones*. El objetivo del documento es presentar la implementación de las pruebas realizadas con diferentes modelos de redes neuronales gráficas explicadas en el proyecto, así como plantear distintas aproximaciones para su codificación.\n",
    "\n",
    "Aunque van a explicarse algunos conceptos relacionados con las librerías de Python utilizadas, se deja en manos de la memoria de proyecto el explicar la base teórica de los mismos, así como la evaluación e interpretación de los resultados obtenidos.\n",
    "\n",
    "## Estructura del documento\n",
    "\n",
    "Mediante el uso del orden presentado en la memoria, se van a repasar distintas aproximaciones a las GNN con dos planteamientos principales:\n",
    "\n",
    "1. Clasificación de nodos dentro de un grafo:\n",
    "    1. Implementación mediante un modelo con base espectral.\n",
    "    1. Implementación con un modelo espacial mediante paso de mensajes.\n",
    "    1. Contraste de resultados frente a un modelo tradicional que no tiene en cuenta la estructura de los datos, en busca de justificar la motivación de la existencia de las redes gráficas.\n",
    "1. Predicción de enlazado.\n",
    "    1. Implementación de un modelo que hace uso de paso de mensajes para predecir enlaces entre nodos.\n",
    "\n",
    "Para cada uno de estos ejemplos se presentarán resultados de métricas de precisión durante el proceso de entrenamiento, para lo que se hará uso de datos de validación, así como pruebas finales sobre datos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno\n",
    "\n",
    "### Instalación de módulos\n",
    "\n",
    "Como primer paso, se procede a instalar los módulos necesarios:\n",
    "\n",
    "* [numpy](https://numpy.org/), para poder realizar las operaciones necesarias sobre los datos.\n",
    "* [TensorFlow](https://www.tensorflow.org/), como librería principal para ejecutar los algoritmos de aprendizaje computacional del bloque de clasificación de nodos.\n",
    "* [Spektral](https://graphneural.network/), una cómoda librería y colección de sets de datos que facilita el trabajo con redes neuronales gráficas.\n",
    "* [PyTorch](https://pytorch.org/), librería de aprendizaje computacional que será usada para las pruebas de predicción de enlaces. Junto a ella se instalarán también algunas sublibrerías que serán necesarias.\n",
    "* [tqdm](https://github.com/tqdm/tqdm), una librería simple para crear barras de progreso, con el simple objetivo de facilitar la lectura de algunas pruebas.\n",
    "\n",
    "A continuación, se hacen las llamadas oportunas para instalar las mismas en el entorno actual. De manera adicional, se adjunta el fichero `requirements.txt` junto con este notebook para su uso en caso de necesidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.19.5)\n",
      "Requirement already satisfied: tensorflow in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: spektral in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: joblib in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.1.0)\n",
      "Requirement already satisfied: networkx in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.6.3)\n",
      "Requirement already satisfied: lxml in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (4.6.4)\n",
      "Requirement already satisfied: scipy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.7.2)\n",
      "Requirement already satisfied: pandas in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.3.4)\n",
      "Requirement already satisfied: tqdm in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (4.62.3)\n",
      "Requirement already satisfied: requests in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.26.0)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.0.1)\n",
      "Requirement already satisfied: numpy<1.20 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.19.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.42.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.37.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (4.0.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.13.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.19.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (12.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.22.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->spektral) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->spektral) (2021.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scikit-learn->spektral) (3.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (57.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.1.1)\n",
      "Requirement already satisfied: torch in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch) (4.0.0)\n",
      "Requirement already satisfied: torch-cluster in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.5.9)\n",
      "Requirement already satisfied: torch-scatter in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (2.0.9)\n",
      "Requirement already satisfied: torch-sparse in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (0.6.12)\n",
      "Requirement already satisfied: scipy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-sparse) (1.7.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scipy->torch-sparse) (1.19.5)\n",
      "Requirement already satisfied: torch-geometric in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: PyYAML in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (6.0)\n",
      "Requirement already satisfied: requests in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: rdflib in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (4.62.3)\n",
      "Requirement already satisfied: googledrivedownloader in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (0.4)\n",
      "Requirement already satisfied: pyparsing in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (3.0.6)\n",
      "Requirement already satisfied: networkx in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (2.6.3)\n",
      "Requirement already satisfied: pandas in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (1.0.1)\n",
      "Requirement already satisfied: scipy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (1.7.2)\n",
      "Requirement already satisfied: yacs in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (0.1.8)\n",
      "Requirement already satisfied: numpy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from torch-geometric) (1.19.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->torch-geometric) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->torch-geometric) (2.8.2)\n",
      "Requirement already satisfied: isodate in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from rdflib->torch-geometric) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from rdflib->torch-geometric) (57.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->torch-geometric) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->torch-geometric) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->torch-geometric) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->torch-geometric) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (4.62.3)\n"
     ]
    }
   ],
   "source": [
    "# Install required modules\n",
    "necessary_modules = ['numpy', 'tensorflow', 'spektral', 'torch', 'torch-cluster', 'torch-scatter', 'torch-sparse', 'torch-geometric', 'tqdm']\n",
    "for module in necessary_modules:\n",
    "    !pip install {module}\n",
    "\n",
    "# Import numpy module, that is going to be use across the project\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de TensorBoard\n",
    "\n",
    "Tanto en los ejemplos donde se hace uso de TensorFlow como en aquellos implementados con PyTorch, se extraerán las métricas de aprendizaje y precisión a ficheros de registro que podrán ser leídos mediante [TensorBoard](https://www.tensorflow.org/tensorboard?hl=en), un entorno del propio TensorFlow que facilita su seguimiento y visualización. \n",
    "\n",
    "Para ello, es preciso preparar un directorio donde guardar el historial de registro de mensajes y configurar el propio entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorBoard callback to be able to use it in all the code samples\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Prepare placement for the logs\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "# Create directory if it doesn't exists\n",
    "from pathlib import Path\n",
    "Path(root_logdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define a function that returns the path to store the log depending on the experiment\n",
    "def get_run_logdir(experiment_name):\n",
    "    import time\n",
    "    run_id = time.strftime(f'run_{experiment_name}_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de pruebas\n",
    "\n",
    "A continuación se presentan las distintas pruebas realizadas.\n",
    "\n",
    "### Pruebas de clasificación de nodos\n",
    "\n",
    "Tal como se expone en la memoria de proyecto, las redes neuronales gráficas permiten, entre otras cosas, la clasificación de nodos en base a la información de sus vecindarios, lo que permite asignar clases dentro del contexto de las entidades de un grafo.\n",
    "\n",
    "Para la realización de estas pruebas se hará uso de la librería Spektral, que ya ha sido instalada con anterioridad. Spektral ofrece una amplia colección de modelos de red neuronal gráfica ya implementados, así como distintas utilidades de código para su explotación. A modo de añadido, también incorpora una clase especial para poder cargar juegos de datos con distintas características, entre los que se encuentra CORA, que ha sido escogido para la realización de estas pruebas.\n",
    "\n",
    "Así, el primer paso será importar el juego de datos y repasarlo, para lo que será preciso cargar la propia librería Spektral, así como TensorFlow y Keras, que pasan a sumarse a numpy, ya cargado, a la lista de módulos utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary librearies and define aliases to refer to them easier\n",
    "import spektral\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set TensorFlow random seed to a fixed value to obtaine the same results\n",
    "tf.random.set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga y preparación del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se indica en la memoria de proyecto, se hará uso del juego de datos conocido como CORA. Gracias a Spektral, es sencillo descargar este juego de datos y sus distintas estructuras ya preparadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# Download CORA dataset and its different members\n",
    "from spektral.transforms import LayerPreprocess\n",
    "from spektral.layers import GCNConv\n",
    "dataset = spektral.datasets.citation.Citation(\n",
    "    'cora', \n",
    "    random_split=False,\n",
    "    normalize_x=True,\n",
    "    transforms=[LayerPreprocess(GCNConv)],\n",
    "    dtype=np.float32\n",
    "    )\n",
    "\n",
    "# Also load a list of labels as names, justo to be able to use it\n",
    "label_names = ['Case_Based', 'Genetic_Algorithms', 'Neural_Networks', \n",
    "    'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto, se pueden consultar las características del conjunto de datos que ha sido descargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Citation(n_graphs=1)\n",
      "First graph: Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)\n",
      "Node labels: Case_Based, Genetic_Algorithms, Neural_Networks, Probabilistic_Methods, Reinforcement_Learning, Rule_Learning, Theory\n",
      "Training samples: 140\n",
      "Validation samples: 500\n",
      "Test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}')\n",
    "print('First graph: {}'.format(dataset.graphs[0]))\n",
    "print('Node labels: {}'.format(', '.join(label_names)))\n",
    "print(f'Training samples: {np.sum(dataset.mask_tr)}')\n",
    "print(f'Validation samples: {np.sum(dataset.mask_va)}')\n",
    "print(f'Test samples: {np.sum(dataset.mask_te)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a los datos extraídos, se puede ver que la variable `dataset` contiene un grafo, el cuál puede ser accedido para conocer sus características. De este modo, se comprueba que el conjunto de datos CORA ha sido descargado y está compuesto por:\n",
    "\n",
    "* 2708 nodos o vértices, que conforman el grafo.\n",
    "* 1433 atributos de nodo.\n",
    "* 0 atributos de relación, es decir, los enlaces que relacionan los nodos no contienen información. Como se explica en la memoria de proyecto, esto impide tener distintas categorías en los vínculos y limitará el aprendizaje al contenido de los nodos y el contexto con el que se relacionan.\n",
    "* 7 clases. En base a la definición del juego de datos, se sabe que los vértices se clasifican en dicho número de grupos. Sin embargo, como se explica en la memoria de proyecto, también es posible hacer uso de GNNs para clasificar grafos, por lo que Spektral nos permite trabajar con dos tipos de etiquetas: de nodo y de grafo.\n",
    "\n",
    "Además, Spektral se encarga de generar los subconjuntos del juego de datos que son necesarios para las pruebas a realizar, que quedan divididos en tres:\n",
    "\n",
    "* Conjunto de entrenamiento, que cuenta con 140 nodos. Es accesible desde `dataset.mask_tr`.\n",
    "* Conjunto de validación, compuesto por 500 vértices. Puede recuperarse mediante `dataset.mask_va`.\n",
    "* Conjunto de pruebas o *test*, formado por 1000 entidades. Se pueden computar desde `dataset.mask_te`.\n",
    "\n",
    "Esta separación en conjuntos de entrenamiento, validación y test se hace mediante un enmascaramiento: están formados por un vector de tipo `narray` con tantas posiciones como nodos hay en el conjunto de datos. En cada posición se registrará un `1` si el vértice correspondiente pertenece al conjunto y con un `0` en caso contrario.\n",
    "\n",
    "Por esta razón, se presenta la posibilidad de generar los pesos de cada vértice según si han sido seleccionados o no. Con el fin de fijar el mismo peso para todos dentro de cada conjunto, se procede a dividir cada uno de ellos por el número de observaciones en su grupo. El resultado es almacenado en `weighted_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples weights: 0.0071428571827709675\n",
      "Validation samples weights: 0.0020000000949949026\n",
      "Test samples weights: 0.0010000001639127731\n"
     ]
    }
   ],
   "source": [
    "weighted_mask = [\n",
    "    mask.astype(np.float32) / np.count_nonzero(mask)\n",
    "    for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te)\n",
    "]\n",
    "\n",
    "print(f'Training samples weights: {np.nanmean(np.where(weighted_mask[0] > 0, weighted_mask[0],np.nan), 0)}')\n",
    "print(f'Validation samples weights: {np.nanmean(np.where(weighted_mask[1] > 0, weighted_mask[1],np.nan), 0)}')\n",
    "print(f'Test samples weights: {np.nanmean(np.where(weighted_mask[2] > 0, weighted_mask[2],np.nan), 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del grafo registrado, es posible acceder a las diferentes estructuras que lo representan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características de los nodos, en formato matriz:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "Matriz de adyacencia, de tipo sparse matrix:\n",
      "  (0, 0)\t0.25\n",
      "  (0, 633)\t0.25\n",
      "  (0, 1862)\t0.2236068\n",
      "  (0, 2582)\t0.25\n",
      "  (1, 1)\t0.25\n",
      "  (1, 2)\t0.20412415\n",
      "  (1, 652)\t0.28867513\n",
      "  (1, 654)\t0.35355338\n",
      "  (2, 1)\t0.20412415\n",
      "  (2, 2)\t0.16666667\n",
      "  (2, 332)\t0.16666667\n",
      "  (2, 1454)\t0.28867513\n",
      "  (2, 1666)\t0.15430336\n",
      "  (2, 1986)\t0.05025189\n",
      "  (3, 3)\t0.49999997\n",
      "  (3, 2544)\t0.49999997\n",
      "  (4, 4)\t0.16666667\n",
      "  (4, 1016)\t0.16666667\n",
      "  (4, 1256)\t0.13608277\n",
      "  (4, 1761)\t0.14433756\n",
      "  (4, 2175)\t0.16666667\n",
      "  (4, 2176)\t0.13608277\n",
      "  (5, 5)\t0.25\n",
      "  (5, 1629)\t0.25\n",
      "  (5, 1659)\t0.28867513\n",
      "  :\t:\n",
      "  (2699, 2699)\t0.49999997\n",
      "  (2700, 1151)\t0.40824828\n",
      "  (2700, 2700)\t0.49999997\n",
      "  (2701, 44)\t0.28867513\n",
      "  (2701, 2624)\t0.3333333\n",
      "  (2701, 2701)\t0.3333333\n",
      "  (2702, 186)\t0.21821788\n",
      "  (2702, 1536)\t0.2581989\n",
      "  (2702, 2702)\t0.3333333\n",
      "  (2703, 1298)\t0.49999997\n",
      "  (2703, 2703)\t0.49999997\n",
      "  (2704, 641)\t0.49999997\n",
      "  (2704, 2704)\t0.49999997\n",
      "  (2705, 287)\t0.49999997\n",
      "  (2705, 2705)\t0.49999997\n",
      "  (2706, 165)\t0.19999999\n",
      "  (2706, 169)\t0.2581989\n",
      "  (2706, 1473)\t0.19999999\n",
      "  (2706, 2706)\t0.19999999\n",
      "  (2706, 2707)\t0.19999999\n",
      "  (2707, 165)\t0.19999999\n",
      "  (2707, 598)\t0.07669649\n",
      "  (2707, 1473)\t0.19999999\n",
      "  (2707, 2706)\t0.19999999\n",
      "  (2707, 2707)\t0.19999999\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Características de los nodos, en formato matriz:\\n{}\\n\\n'.format(dataset.graphs[0].x))\n",
    "print('Matriz de adyacencia, de tipo sparse matrix:\\n{}\\n\\n'.format(dataset.graphs[0].a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características de las aristas, en formato matriz (vacía, en este caso):\n",
      "None\n",
      "\n",
      "\n",
      "Etiquetas de cada nodo:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Características de las aristas, en formato matriz (vacía, en este caso):\\n{}\\n\\n'.format(dataset.graphs[0].e))\n",
    "print('Etiquetas de cada nodo:\\n{}'.format(dataset.graphs[0].y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 1: Implementación ConvGNN espectral\n",
    "\n",
    "Gracias al fichero de datos preparado, es posible probar la implementación de uno de los modelos presentados en la memoria de proyecto: una red neuronal convolucional gráfica o ConvGNN con una aproximación espectral.\n",
    "\n",
    "Como se explica en el documento de proyecto, el uso de la estructural espectral permite el aprendizaje y predicción en base a la estructura general del grafo, por lo que se hará uso de la matriz de adyacencia y las características de los nodos, pero sin la posibilidad de tener en cuenta la estructura general, algo que veremos en mayor detalle en la implementación de una ConvGNN espacial en el siguiente apartado.\n",
    "\n",
    "El primer paso será cargar los datos en un `Loader`, una clase dentro de Spektral que se encarga de gestionar el conjunto de datos y devolver los subconjuntos necesarios para el entrenamiento de la red neuronal. Así, se procede a crear uno para el conjunto de entrenamiento y otro para el de validación. Puesto que el ejemplo está destinado a aprender de una única representación de grafo, se usará un `SingleLoader` y se le pasarán los pesos de los nodos, con el fin de tenerlos en cuenta en la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data.loaders import SingleLoader\n",
    "loader_training = SingleLoader(dataset, sample_weights=weighted_mask[0])\n",
    "loader_validation = SingleLoader(dataset, sample_weights=weighted_mask[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante la fase de entrenamiento, cada loader devolverá una tupla compuesta por una tupla que contendrá los inputs del modelo, las etiquetas de cada nodo y los pesos de los mismos desde la estructura pasada como `sample_weights`.\n",
    "\n",
    "Con los datos listos para ser usados, el siguiente paso será crear el modelo desde Spektral. En este caso, se hará uso de la clase `GCN` de Spektral, la cuál hace uso de la arquitectura propuesta en el paper de Kipf y Welling de 2016 (**REFERENCIA** desde memoria). La instancia se crea mediante el paso de:\n",
    "\n",
    "1. Número de etiquetas de nodo mediante `n_labels`, dato que se recoge desde el conjunto de datos creado.\n",
    "1. Número de características de nodos mediante `n_input_channels`. Tal como se explica en la memoria, este modelo básico de red convolucional gráfica hace uso de las características de cada nodo y las relaciones de su entorno, pero no tiene en cuenta las propiedades de los enlaces entre vértices, por lo que estas son ignoradas como entrada.\n",
    "\n",
    "Además, se pueden destacar algunas propiedades adicionales:\n",
    "\n",
    "* Se fija un ritmo de aprendizaje de 0.01.\n",
    "* Se elige la función de suma como método de agregación.\n",
    "* Se utiliza el optimizador `Adam`.\n",
    "* Se opta por *cross entropy* como función de pérdida.\n",
    "* Se configura la métrica de precisión para su seguimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.models.gcn import GCN # Import model\n",
    "from tensorflow.keras.optimizers import Adam # Import optimizers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy # Import loss function from Keras\n",
    "\n",
    "# Set initial configuration\n",
    "learning_rate = 1e-2\n",
    "reduction_function = 'sum'\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_function = CategoricalCrossentropy(reduction=reduction_function)\n",
    "metrics_to_evaluate = ['acc']\n",
    "\n",
    "# Create model from Spektral\n",
    "model_gcn = GCN(n_labels=dataset.n_labels, n_input_channels=dataset.n_node_features)\n",
    "\n",
    "# Compile loaded model\n",
    "model_gcn.compile(\n",
    "    optimizer=optimizer, loss=loss_function, weighted_metrics=metrics_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo listo, es posible proceder a llevar a cabo su entrenamiento. Con el fin de detener el proceso tan pronto como se detecte que la precisión no progresa, se hace uso del callback `EartlyStopping` de Keras con una paciencia de `10`, lo que establece que el proceso se detendrá si pasado dicho número de épocas (*epochs*) no se detecta una mejora en los resultados. De igual manera, se establece un máximo de `200` épocas de entrenamiento.\n",
    "\n",
    "Para terminar, se añade un callback para enviar los resultados a TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.9541 - acc: 0.1071 - val_loss: 1.9512 - val_acc: 0.2660\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9482 - acc: 0.3071 - val_loss: 1.9482 - val_acc: 0.3800\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.9422 - acc: 0.5571 - val_loss: 1.9451 - val_acc: 0.4020\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.9372 - acc: 0.5571 - val_loss: 1.9420 - val_acc: 0.3980\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.9288 - acc: 0.6143 - val_loss: 1.9391 - val_acc: 0.3760\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.9188 - acc: 0.6571 - val_loss: 1.9366 - val_acc: 0.3380\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9119 - acc: 0.6143 - val_loss: 1.9343 - val_acc: 0.3140\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9054 - acc: 0.5500 - val_loss: 1.9320 - val_acc: 0.2980\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8978 - acc: 0.5643 - val_loss: 1.9297 - val_acc: 0.2920\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8885 - acc: 0.5786 - val_loss: 1.9272 - val_acc: 0.2920\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8756 - acc: 0.6000 - val_loss: 1.9247 - val_acc: 0.2900\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.8711 - acc: 0.6071 - val_loss: 1.9222 - val_acc: 0.2940\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8578 - acc: 0.6286 - val_loss: 1.9197 - val_acc: 0.2960\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.8542 - acc: 0.6286 - val_loss: 1.9172 - val_acc: 0.2960\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.8422 - acc: 0.6500 - val_loss: 1.9148 - val_acc: 0.2980\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.8368 - acc: 0.6214 - val_loss: 1.9124 - val_acc: 0.2980\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.8263 - acc: 0.6071 - val_loss: 1.9098 - val_acc: 0.3020\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.8058 - acc: 0.6500 - val_loss: 1.9072 - val_acc: 0.3040\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7926 - acc: 0.7143 - val_loss: 1.9046 - val_acc: 0.3080\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.7933 - acc: 0.6643 - val_loss: 1.9019 - val_acc: 0.3120\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7759 - acc: 0.6429 - val_loss: 1.8991 - val_acc: 0.3140\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7618 - acc: 0.6286 - val_loss: 1.8963 - val_acc: 0.3160\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7613 - acc: 0.6786 - val_loss: 1.8934 - val_acc: 0.3240\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.7423 - acc: 0.7286 - val_loss: 1.8904 - val_acc: 0.3260\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7198 - acc: 0.7000 - val_loss: 1.8874 - val_acc: 0.3300\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7261 - acc: 0.6214 - val_loss: 1.8843 - val_acc: 0.3300\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.7079 - acc: 0.6429 - val_loss: 1.8810 - val_acc: 0.3360\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.6903 - acc: 0.6857 - val_loss: 1.8777 - val_acc: 0.3360\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6916 - acc: 0.6786 - val_loss: 1.8742 - val_acc: 0.3380\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6654 - acc: 0.7000 - val_loss: 1.8706 - val_acc: 0.3460\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6341 - acc: 0.6857 - val_loss: 1.8669 - val_acc: 0.3540\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6411 - acc: 0.6786 - val_loss: 1.8631 - val_acc: 0.3540\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6012 - acc: 0.7000 - val_loss: 1.8593 - val_acc: 0.3600\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6328 - acc: 0.6786 - val_loss: 1.8553 - val_acc: 0.3740\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5981 - acc: 0.6929 - val_loss: 1.8511 - val_acc: 0.3720\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5840 - acc: 0.7429 - val_loss: 1.8471 - val_acc: 0.3780\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5505 - acc: 0.7000 - val_loss: 1.8429 - val_acc: 0.3820\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5795 - acc: 0.7143 - val_loss: 1.8385 - val_acc: 0.3920\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5869 - acc: 0.7071 - val_loss: 1.8339 - val_acc: 0.3960\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5522 - acc: 0.7500 - val_loss: 1.8291 - val_acc: 0.3980\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5099 - acc: 0.7500 - val_loss: 1.8244 - val_acc: 0.4120\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5275 - acc: 0.7214 - val_loss: 1.8193 - val_acc: 0.4180\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5074 - acc: 0.7571 - val_loss: 1.8140 - val_acc: 0.4240\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4955 - acc: 0.7357 - val_loss: 1.8085 - val_acc: 0.4300\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4784 - acc: 0.7286 - val_loss: 1.8028 - val_acc: 0.4360\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4515 - acc: 0.7643 - val_loss: 1.7968 - val_acc: 0.4400\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4598 - acc: 0.7286 - val_loss: 1.7905 - val_acc: 0.4440\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4487 - acc: 0.8000 - val_loss: 1.7843 - val_acc: 0.4520\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4006 - acc: 0.7929 - val_loss: 1.7780 - val_acc: 0.4580\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4278 - acc: 0.7643 - val_loss: 1.7712 - val_acc: 0.4640\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3965 - acc: 0.7786 - val_loss: 1.7642 - val_acc: 0.4660\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3601 - acc: 0.7786 - val_loss: 1.7571 - val_acc: 0.4700\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3541 - acc: 0.7857 - val_loss: 1.7499 - val_acc: 0.4820\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3703 - acc: 0.8143 - val_loss: 1.7426 - val_acc: 0.4940\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3504 - acc: 0.8071 - val_loss: 1.7351 - val_acc: 0.5020\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3279 - acc: 0.8143 - val_loss: 1.7278 - val_acc: 0.5100\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2900 - acc: 0.8714 - val_loss: 1.7204 - val_acc: 0.5200\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2983 - acc: 0.8857 - val_loss: 1.7131 - val_acc: 0.5220\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3117 - acc: 0.8571 - val_loss: 1.7056 - val_acc: 0.5320\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2598 - acc: 0.8429 - val_loss: 1.6978 - val_acc: 0.5340\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2888 - acc: 0.8429 - val_loss: 1.6901 - val_acc: 0.5400\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2679 - acc: 0.8571 - val_loss: 1.6823 - val_acc: 0.5500\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2086 - acc: 0.9000 - val_loss: 1.6744 - val_acc: 0.5580\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2615 - acc: 0.8929 - val_loss: 1.6665 - val_acc: 0.5720\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2398 - acc: 0.8500 - val_loss: 1.6586 - val_acc: 0.5880\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2026 - acc: 0.8643 - val_loss: 1.6505 - val_acc: 0.5980\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1967 - acc: 0.9000 - val_loss: 1.6424 - val_acc: 0.6240\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1713 - acc: 0.9000 - val_loss: 1.6342 - val_acc: 0.6340\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1766 - acc: 0.8929 - val_loss: 1.6259 - val_acc: 0.6480\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2356 - acc: 0.8786 - val_loss: 1.6174 - val_acc: 0.6600\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1627 - acc: 0.9071 - val_loss: 1.6088 - val_acc: 0.6660\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1357 - acc: 0.8786 - val_loss: 1.6001 - val_acc: 0.6760\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1517 - acc: 0.8857 - val_loss: 1.5912 - val_acc: 0.6780\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1236 - acc: 0.8929 - val_loss: 1.5820 - val_acc: 0.6860\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1215 - acc: 0.9214 - val_loss: 1.5733 - val_acc: 0.6940\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1036 - acc: 0.9214 - val_loss: 1.5649 - val_acc: 0.7040\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0760 - acc: 0.9071 - val_loss: 1.5562 - val_acc: 0.7080\n",
      "Epoch 78/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0990 - acc: 0.9214 - val_loss: 1.5474 - val_acc: 0.7180\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0955 - acc: 0.9214 - val_loss: 1.5388 - val_acc: 0.7220\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0807 - acc: 0.9071 - val_loss: 1.5304 - val_acc: 0.7240\n",
      "Epoch 81/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0536 - acc: 0.9286 - val_loss: 1.5224 - val_acc: 0.7300\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9925 - acc: 0.9643 - val_loss: 1.5147 - val_acc: 0.7400\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0771 - acc: 0.9214 - val_loss: 1.5071 - val_acc: 0.7400\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0729 - acc: 0.9429 - val_loss: 1.4996 - val_acc: 0.7420\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0080 - acc: 0.9286 - val_loss: 1.4925 - val_acc: 0.7440\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0140 - acc: 0.9143 - val_loss: 1.4857 - val_acc: 0.7460\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0454 - acc: 0.9214 - val_loss: 1.4792 - val_acc: 0.7460\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0289 - acc: 0.8857 - val_loss: 1.4727 - val_acc: 0.7500\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0022 - acc: 0.9500 - val_loss: 1.4662 - val_acc: 0.7520\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0089 - acc: 0.9786 - val_loss: 1.4600 - val_acc: 0.7540\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0338 - acc: 0.9357 - val_loss: 1.4537 - val_acc: 0.7540\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9708 - acc: 0.9429 - val_loss: 1.4466 - val_acc: 0.7560\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9346 - acc: 0.9357 - val_loss: 1.4396 - val_acc: 0.7580\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9991 - acc: 0.9500 - val_loss: 1.4326 - val_acc: 0.7580\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9574 - acc: 0.9357 - val_loss: 1.4255 - val_acc: 0.7580\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9935 - acc: 0.9357 - val_loss: 1.4184 - val_acc: 0.7600\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9769 - acc: 0.9286 - val_loss: 1.4118 - val_acc: 0.7600\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9470 - acc: 0.9643 - val_loss: 1.4052 - val_acc: 0.7600\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9342 - acc: 0.9429 - val_loss: 1.3990 - val_acc: 0.7620\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9354 - acc: 0.9357 - val_loss: 1.3931 - val_acc: 0.7620\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8963 - acc: 0.9500 - val_loss: 1.3871 - val_acc: 0.7620\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8914 - acc: 0.9357 - val_loss: 1.3817 - val_acc: 0.7620\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8915 - acc: 0.9571 - val_loss: 1.3763 - val_acc: 0.7620\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9402 - acc: 0.9143 - val_loss: 1.3708 - val_acc: 0.7640\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8631 - acc: 0.9357 - val_loss: 1.3654 - val_acc: 0.7660\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9133 - acc: 0.9357 - val_loss: 1.3600 - val_acc: 0.7660\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8941 - acc: 0.9357 - val_loss: 1.3543 - val_acc: 0.7700\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8720 - acc: 0.9571 - val_loss: 1.3492 - val_acc: 0.7700\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9157 - acc: 0.9429 - val_loss: 1.3444 - val_acc: 0.7740\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8750 - acc: 0.9357 - val_loss: 1.3398 - val_acc: 0.7740\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8504 - acc: 0.9429 - val_loss: 1.3353 - val_acc: 0.7740\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8267 - acc: 0.9857 - val_loss: 1.3310 - val_acc: 0.7760\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8791 - acc: 0.9357 - val_loss: 1.3268 - val_acc: 0.7760\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8037 - acc: 0.9786 - val_loss: 1.3224 - val_acc: 0.7720\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8559 - acc: 0.9357 - val_loss: 1.3181 - val_acc: 0.7720\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8284 - acc: 0.9429 - val_loss: 1.3142 - val_acc: 0.7740\n",
      "Epoch 117/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8676 - acc: 0.9500 - val_loss: 1.3096 - val_acc: 0.7740\n",
      "Epoch 118/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8121 - acc: 0.9714 - val_loss: 1.3051 - val_acc: 0.7760\n",
      "Epoch 119/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8591 - acc: 0.9500 - val_loss: 1.3004 - val_acc: 0.7760\n",
      "Epoch 120/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8029 - acc: 0.9714 - val_loss: 1.2953 - val_acc: 0.7820\n",
      "Epoch 121/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8671 - acc: 0.9357 - val_loss: 1.2905 - val_acc: 0.7780\n",
      "Epoch 122/400\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8376 - acc: 0.9357 - val_loss: 1.2856 - val_acc: 0.7780\n",
      "Epoch 123/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7722 - acc: 0.9500 - val_loss: 1.2810 - val_acc: 0.7760\n",
      "Epoch 124/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8139 - acc: 0.9429 - val_loss: 1.2763 - val_acc: 0.7760\n",
      "Epoch 125/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7597 - acc: 0.9643 - val_loss: 1.2721 - val_acc: 0.7760\n",
      "Epoch 126/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8272 - acc: 0.9286 - val_loss: 1.2680 - val_acc: 0.7760\n",
      "Epoch 127/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8111 - acc: 0.9357 - val_loss: 1.2639 - val_acc: 0.7780\n",
      "Epoch 128/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7996 - acc: 0.9714 - val_loss: 1.2598 - val_acc: 0.7800\n",
      "Epoch 129/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8482 - acc: 0.9286 - val_loss: 1.2555 - val_acc: 0.7800\n",
      "Epoch 130/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8371 - acc: 0.9429 - val_loss: 1.2514 - val_acc: 0.7800\n",
      "Epoch 131/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7386 - acc: 0.9714 - val_loss: 1.2474 - val_acc: 0.7800\n",
      "Epoch 132/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7896 - acc: 0.9714 - val_loss: 1.2440 - val_acc: 0.7800\n",
      "Epoch 133/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7946 - acc: 0.9429 - val_loss: 1.2410 - val_acc: 0.7820\n",
      "Epoch 134/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7539 - acc: 0.9714 - val_loss: 1.2378 - val_acc: 0.7840\n",
      "Epoch 135/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7952 - acc: 0.9357 - val_loss: 1.2347 - val_acc: 0.7840\n",
      "Epoch 136/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8043 - acc: 0.9571 - val_loss: 1.2318 - val_acc: 0.7840\n",
      "Epoch 137/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8262 - acc: 0.9214 - val_loss: 1.2292 - val_acc: 0.7820\n",
      "Epoch 138/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7232 - acc: 0.9571 - val_loss: 1.2268 - val_acc: 0.7820\n",
      "Epoch 139/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7793 - acc: 0.9571 - val_loss: 1.2247 - val_acc: 0.7820\n",
      "Epoch 140/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7301 - acc: 0.9643 - val_loss: 1.2221 - val_acc: 0.7800\n",
      "Epoch 141/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7619 - acc: 0.9357 - val_loss: 1.2198 - val_acc: 0.7800\n",
      "Epoch 142/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7373 - acc: 0.9500 - val_loss: 1.2177 - val_acc: 0.7800\n",
      "Epoch 143/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7513 - acc: 0.9500 - val_loss: 1.2154 - val_acc: 0.7800\n",
      "Epoch 144/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7365 - acc: 0.9286 - val_loss: 1.2130 - val_acc: 0.7800\n",
      "Epoch 145/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7003 - acc: 0.9786 - val_loss: 1.2102 - val_acc: 0.7820\n",
      "Epoch 146/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7415 - acc: 0.9500 - val_loss: 1.2074 - val_acc: 0.7820\n",
      "Epoch 147/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7387 - acc: 0.9643 - val_loss: 1.2052 - val_acc: 0.7820\n",
      "Epoch 148/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7294 - acc: 0.9357 - val_loss: 1.2024 - val_acc: 0.7800\n",
      "Epoch 149/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7365 - acc: 0.9429 - val_loss: 1.1991 - val_acc: 0.7800\n",
      "Epoch 150/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7344 - acc: 0.9500 - val_loss: 1.1957 - val_acc: 0.7820\n",
      "Epoch 151/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6897 - acc: 0.9643 - val_loss: 1.1924 - val_acc: 0.7820\n",
      "Epoch 152/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7357 - acc: 0.9286 - val_loss: 1.1895 - val_acc: 0.7840\n",
      "Epoch 153/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7245 - acc: 0.9571 - val_loss: 1.1865 - val_acc: 0.7880\n",
      "Epoch 154/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7847 - acc: 0.9429 - val_loss: 1.1834 - val_acc: 0.7900\n",
      "Epoch 155/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7531 - acc: 0.9357 - val_loss: 1.1800 - val_acc: 0.7900\n",
      "Epoch 156/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7141 - acc: 0.9714 - val_loss: 1.1767 - val_acc: 0.7940\n",
      "Epoch 157/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7351 - acc: 0.9286 - val_loss: 1.1738 - val_acc: 0.7940\n",
      "Epoch 158/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7599 - acc: 0.9500 - val_loss: 1.1709 - val_acc: 0.7940\n",
      "Epoch 159/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7188 - acc: 0.9857 - val_loss: 1.1685 - val_acc: 0.7940\n",
      "Epoch 160/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7297 - acc: 0.9286 - val_loss: 1.1664 - val_acc: 0.7940\n",
      "Epoch 161/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7177 - acc: 0.9571 - val_loss: 1.1643 - val_acc: 0.7940\n",
      "Epoch 162/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6909 - acc: 0.9500 - val_loss: 1.1622 - val_acc: 0.7960\n",
      "Epoch 163/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7226 - acc: 0.9500 - val_loss: 1.1601 - val_acc: 0.7960\n",
      "Epoch 164/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7338 - acc: 0.9643 - val_loss: 1.1583 - val_acc: 0.7980\n",
      "Epoch 165/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6738 - acc: 0.9714 - val_loss: 1.1561 - val_acc: 0.7980\n",
      "Epoch 166/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7383 - acc: 0.9643 - val_loss: 1.1539 - val_acc: 0.7980\n",
      "Epoch 167/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6481 - acc: 0.9571 - val_loss: 1.1518 - val_acc: 0.7980\n",
      "Epoch 168/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6862 - acc: 0.9786 - val_loss: 1.1496 - val_acc: 0.7980\n",
      "Epoch 169/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7003 - acc: 0.9571 - val_loss: 1.1479 - val_acc: 0.7960\n",
      "Epoch 170/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6664 - acc: 0.9786 - val_loss: 1.1463 - val_acc: 0.7960\n",
      "Epoch 171/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6956 - acc: 0.9643 - val_loss: 1.1454 - val_acc: 0.7960\n",
      "Epoch 172/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6764 - acc: 0.9429 - val_loss: 1.1446 - val_acc: 0.7960\n",
      "Epoch 173/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6816 - acc: 0.9571 - val_loss: 1.1436 - val_acc: 0.7960\n",
      "Epoch 174/400\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7178 - acc: 0.9500 - val_loss: 1.1426 - val_acc: 0.7980\n",
      "Epoch 175/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6597 - acc: 0.9643 - val_loss: 1.1412 - val_acc: 0.7980\n",
      "Epoch 176/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6660 - acc: 0.9643 - val_loss: 1.1400 - val_acc: 0.7940\n",
      "Epoch 177/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6823 - acc: 0.9571 - val_loss: 1.1386 - val_acc: 0.7920\n",
      "Epoch 178/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6351 - acc: 0.9929 - val_loss: 1.1369 - val_acc: 0.7920\n",
      "Epoch 179/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6405 - acc: 0.9643 - val_loss: 1.1350 - val_acc: 0.7900\n",
      "Epoch 180/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6590 - acc: 0.9714 - val_loss: 1.1328 - val_acc: 0.7900\n",
      "Epoch 181/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6814 - acc: 0.9357 - val_loss: 1.1313 - val_acc: 0.7900\n",
      "Epoch 182/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7008 - acc: 0.9571 - val_loss: 1.1302 - val_acc: 0.7900\n",
      "Epoch 183/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6542 - acc: 0.9643 - val_loss: 1.1291 - val_acc: 0.7900\n",
      "Epoch 184/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6227 - acc: 0.9786 - val_loss: 1.1277 - val_acc: 0.7900\n",
      "Epoch 185/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6833 - acc: 0.9429 - val_loss: 1.1259 - val_acc: 0.7900\n",
      "Epoch 186/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6678 - acc: 0.9643 - val_loss: 1.1246 - val_acc: 0.7880\n",
      "Epoch 187/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6708 - acc: 0.9571 - val_loss: 1.1231 - val_acc: 0.7880\n",
      "Epoch 188/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6273 - acc: 0.9714 - val_loss: 1.1216 - val_acc: 0.7880\n",
      "Epoch 189/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6263 - acc: 0.9429 - val_loss: 1.1195 - val_acc: 0.7880\n",
      "Epoch 190/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6457 - acc: 0.9571 - val_loss: 1.1173 - val_acc: 0.7880\n",
      "Epoch 191/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6669 - acc: 0.9500 - val_loss: 1.1148 - val_acc: 0.7900\n",
      "Epoch 192/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6622 - acc: 0.9571 - val_loss: 1.1126 - val_acc: 0.7900\n",
      "Epoch 193/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6179 - acc: 0.9571 - val_loss: 1.1102 - val_acc: 0.7900\n",
      "Epoch 194/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6242 - acc: 0.9500 - val_loss: 1.1086 - val_acc: 0.7920\n",
      "Epoch 195/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6391 - acc: 0.9786 - val_loss: 1.1068 - val_acc: 0.7920\n",
      "Epoch 196/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6272 - acc: 0.9857 - val_loss: 1.1048 - val_acc: 0.7920\n",
      "Epoch 197/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6317 - acc: 0.9786 - val_loss: 1.1031 - val_acc: 0.7920\n",
      "Epoch 198/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6593 - acc: 0.9714 - val_loss: 1.1026 - val_acc: 0.7920\n",
      "Epoch 199/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6486 - acc: 0.9571 - val_loss: 1.1019 - val_acc: 0.7900\n",
      "Epoch 200/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6282 - acc: 0.9500 - val_loss: 1.1003 - val_acc: 0.7900\n",
      "Epoch 201/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6428 - acc: 0.9357 - val_loss: 1.0980 - val_acc: 0.7900\n",
      "Epoch 202/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6588 - acc: 0.9571 - val_loss: 1.0960 - val_acc: 0.7900\n",
      "Epoch 203/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6035 - acc: 0.9714 - val_loss: 1.0941 - val_acc: 0.7900\n",
      "Epoch 204/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6543 - acc: 0.9643 - val_loss: 1.0924 - val_acc: 0.7900\n",
      "Epoch 205/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5971 - acc: 0.9571 - val_loss: 1.0908 - val_acc: 0.7900\n",
      "Epoch 206/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6605 - acc: 0.9571 - val_loss: 1.0885 - val_acc: 0.7880\n",
      "Epoch 207/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6037 - acc: 0.9714 - val_loss: 1.0865 - val_acc: 0.7900\n",
      "Epoch 208/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6648 - acc: 0.9429 - val_loss: 1.0847 - val_acc: 0.7900\n",
      "Epoch 209/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6225 - acc: 0.9643 - val_loss: 1.0834 - val_acc: 0.7900\n",
      "Epoch 210/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6320 - acc: 0.9500 - val_loss: 1.0825 - val_acc: 0.7880\n",
      "Epoch 211/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6148 - acc: 0.9786 - val_loss: 1.0816 - val_acc: 0.7880\n",
      "Epoch 212/400\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6208 - acc: 0.9786 - val_loss: 1.0809 - val_acc: 0.7900\n",
      "Epoch 213/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6121 - acc: 0.9643 - val_loss: 1.0795 - val_acc: 0.7900\n",
      "Epoch 214/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5836 - acc: 0.9643 - val_loss: 1.0775 - val_acc: 0.7880\n",
      "Epoch 215/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6109 - acc: 0.9500 - val_loss: 1.0766 - val_acc: 0.7880\n",
      "Epoch 216/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5958 - acc: 0.9643 - val_loss: 1.0754 - val_acc: 0.7860\n",
      "Epoch 217/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5742 - acc: 0.9714 - val_loss: 1.0743 - val_acc: 0.7860\n",
      "Epoch 218/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5988 - acc: 0.9571 - val_loss: 1.0729 - val_acc: 0.7860\n",
      "Epoch 219/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6069 - acc: 0.9643 - val_loss: 1.0711 - val_acc: 0.7860\n",
      "Epoch 220/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5725 - acc: 0.9643 - val_loss: 1.0695 - val_acc: 0.7900\n",
      "Epoch 221/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5943 - acc: 0.9929 - val_loss: 1.0679 - val_acc: 0.7880\n",
      "Epoch 222/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5889 - acc: 0.9571 - val_loss: 1.0668 - val_acc: 0.7880\n",
      "Epoch 223/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5815 - acc: 0.9571 - val_loss: 1.0668 - val_acc: 0.7880\n",
      "Epoch 224/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5734 - acc: 0.9786 - val_loss: 1.0672 - val_acc: 0.7900\n",
      "Epoch 225/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5428 - acc: 0.9714 - val_loss: 1.0678 - val_acc: 0.7900\n",
      "Epoch 226/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5930 - acc: 0.9357 - val_loss: 1.0685 - val_acc: 0.7920\n",
      "Epoch 227/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5851 - acc: 0.9714 - val_loss: 1.0686 - val_acc: 0.7920\n",
      "Epoch 228/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6101 - acc: 0.9357 - val_loss: 1.0680 - val_acc: 0.7920\n",
      "Epoch 229/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6296 - acc: 0.9429 - val_loss: 1.0679 - val_acc: 0.7920\n",
      "Epoch 230/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5978 - acc: 0.9571 - val_loss: 1.0666 - val_acc: 0.7900\n",
      "Epoch 231/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6148 - acc: 0.9429 - val_loss: 1.0648 - val_acc: 0.7860\n",
      "Epoch 232/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5828 - acc: 0.9571 - val_loss: 1.0632 - val_acc: 0.7840\n",
      "Epoch 233/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5898 - acc: 0.9571 - val_loss: 1.0611 - val_acc: 0.7860\n",
      "Epoch 234/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5617 - acc: 0.9857 - val_loss: 1.0584 - val_acc: 0.7880\n",
      "Epoch 235/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6049 - acc: 0.9357 - val_loss: 1.0552 - val_acc: 0.7880\n",
      "Epoch 236/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5612 - acc: 0.9714 - val_loss: 1.0533 - val_acc: 0.7900\n",
      "Epoch 237/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5559 - acc: 0.9786 - val_loss: 1.0518 - val_acc: 0.7900\n",
      "Epoch 238/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6467 - acc: 0.9286 - val_loss: 1.0503 - val_acc: 0.7880\n",
      "Epoch 239/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6224 - acc: 0.9214 - val_loss: 1.0494 - val_acc: 0.7880\n",
      "Epoch 240/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5826 - acc: 0.9500 - val_loss: 1.0479 - val_acc: 0.7920\n",
      "Epoch 241/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6151 - acc: 0.9357 - val_loss: 1.0467 - val_acc: 0.7900\n",
      "Epoch 242/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5307 - acc: 0.9786 - val_loss: 1.0449 - val_acc: 0.7900\n",
      "Epoch 243/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5711 - acc: 0.9786 - val_loss: 1.0434 - val_acc: 0.7920\n",
      "Epoch 244/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5779 - acc: 0.9571 - val_loss: 1.0425 - val_acc: 0.7920\n",
      "Epoch 245/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5654 - acc: 0.9786 - val_loss: 1.0419 - val_acc: 0.7900\n",
      "Epoch 246/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5629 - acc: 0.9643 - val_loss: 1.0412 - val_acc: 0.7880\n",
      "Epoch 247/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5909 - acc: 0.9429 - val_loss: 1.0422 - val_acc: 0.7840\n",
      "Epoch 248/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6128 - acc: 0.9500 - val_loss: 1.0435 - val_acc: 0.7880\n",
      "Epoch 249/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6266 - acc: 0.9357 - val_loss: 1.0450 - val_acc: 0.7880\n",
      "Epoch 250/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6118 - acc: 0.9643 - val_loss: 1.0466 - val_acc: 0.7900\n",
      "Epoch 251/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5571 - acc: 0.9571 - val_loss: 1.0475 - val_acc: 0.7880\n",
      "Epoch 252/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5680 - acc: 0.9571 - val_loss: 1.0481 - val_acc: 0.7880\n",
      "Epoch 253/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5663 - acc: 0.9786 - val_loss: 1.0490 - val_acc: 0.7880\n",
      "Epoch 254/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5583 - acc: 0.9571 - val_loss: 1.0497 - val_acc: 0.7860\n",
      "Epoch 255/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5319 - acc: 0.9786 - val_loss: 1.0503 - val_acc: 0.7860\n",
      "Epoch 256/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5524 - acc: 0.9571 - val_loss: 1.0501 - val_acc: 0.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146fcb3d0>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eartly stopping settings\n",
    "early_stopping_patience = 10\n",
    "max_number_of_epochs = 400\n",
    "\n",
    "# Fit the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model_gcn.fit(\n",
    "    loader_training.load(),\n",
    "    steps_per_epoch=loader_training.steps_per_epoch,\n",
    "    validation_data=loader_validation.load(),\n",
    "    validation_steps=loader_validation.steps_per_epoch,\n",
    "    epochs=max_number_of_epochs,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=early_stopping_patience,  restore_best_weights=True),\n",
    "        TensorBoard(get_run_logdir('gcn_spectral'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo ya entrenado, es posible evaluar su precisión frente al juego de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0007 - acc: 0.8090\n",
      "Test loss: 1.0007295608520508\n",
      "Test accuracy: 0.8090001940727234\n"
     ]
    }
   ],
   "source": [
    "loader_te = SingleLoader(dataset, sample_weights=weighted_mask[2])\n",
    "results = model_gcn.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "\n",
    "print(f'Test loss: {results[0]}')\n",
    "print(f'Test accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Añadir número de referencia desde memoria cuando esté todo listo\n",
    "# TODO Aclarar uso de Adam\n",
    "# TODO Probar con otros modelos mediante GridSearch (si nos da tiempo)\n",
    "\n",
    "# TODO Probar sobre conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 2: ConvGNN espacial mediante paso de mensajes: MPNN\n",
    "\n",
    "En el ejemplo anterior se ha basado el aprendizaje y la clasificación en la estructura espectral de los datos cargados, es decir, en la estructura de la matriz de adyacencia. Sin embargo, tal y como se explica en la memoria de proyecto, esta aproximación puede ser pobre para escenarios donde las relaciones (aristas) entre entidades (vértices) del grafo tienen un significado o importancia diferente, o cuando el contexto de un nodo, construido mediante los atributos de sus vecinos, es importante para la clasificación.\n",
    "\n",
    "Para poder preparar este ejemplo, se hará uso de la clase `MessagePassing` de Spektral, que ofrece una API ya preparada para configurar la función de activación y personalizar el comportamiento para distintos juegos de datos. Así, será preciso personalizar:\n",
    "\n",
    "* Función para la construcción del mensaje pasado entre dos vértices vía la arista que los une. Es conocida como `message` dentro de la API de Spektral.\n",
    "* Selección de la función de agregación de los mensajes pasados desde cada arista a cada nodo: suma, media, etc. Aparece definida como `aggregate`.\n",
    "\n",
    "Puesto que las GNN basadas en paso de mensajes requieren sucesivas iteraciones que permitan propagar los mensajes a niveles cada vez más lejanos, la función `propagate` lo ejecuta y computa los atributos de cada nodo tras pasar los mensajes de todas las aristas del grafo y computar la correspondiente función de agregación.\n",
    "\n",
    "Puesto que Spektral está construido sobre Keras, es preciso, además, implementar algunos de los métodos heredados de la clase `Layer` para definir la capa gráfica espacial:\n",
    "\n",
    "* `__init__`, donde se define la función de activación, se pasan el resto de hiperparámetros estándar y se guarda el dato del tamaño de la salida, que será usado más adelante.\n",
    "* `build`, cuya misión es la de inicializar los pesos de la capa mediante la llamada a `add_weight` y asignar el tamaño que tendrá la matriz utilizada para almacenar los pesos dentro de la capa. La matriz de pesos tendrá tantas filas como la entrada y columnas como la salida.\n",
    "* `call` es el método encargado de ejecutar los cálculos de la capa. Puesto que estamos hablando de paso de mensajes, la salida de la capa será función de las característica de los nodos de entrada y los pesos de la capa. Al final de la misma, en lugar de llamar a la función de activación, se llama a `propagate`, un método disponible dentro de `MessagePassing` encargado de realizar la propagación de los mensajes de cada nodo a sus vecinos.\n",
    "\n",
    "A estos métodos estándar, se incorporan otros de la propia API de Spektral, especializados en el trabajo con redes gráficas:\n",
    "\n",
    "* `message`, encargado de componer el mensaje que será pasado entre los nodos. En este ejemplo se hace uso de la información de los nodos vecinos, accesibles mediante `get_j`.\n",
    "* `aggregate`, con el cometido de definir la función de agregación para los mensajes del vecindario. Aquí se hace uso de la media de todos los mensajes del vecindario, aunque una posible mejora del modelo podría ser el uso de hiperparámetros para encontrar la que mejores reusltados pueda dar. Esta opción es posible desde el propio constructor.\n",
    "* `update` donde, ahora sí, se hace uso de la función de activaciónn apra actualizar la matriz de pesos.\n",
    "\n",
    "Con todo, se empieza creando la clase MPNNLayer como herencia `MessagePassing` para preparar la personalización de los citados métodos y definir la capa de paso de mensajes del modelo a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import MessagePassing\n",
    "\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, n_out, activation, **kwargs):\n",
    "        # Initialize message passing layer with the activation function chosen when creating the model\n",
    "        super().__init__(activation=activation, **kwargs)\n",
    "        self.n_out = n_out\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(batch_input_shape[0][-1], self.n_out)\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "\n",
    "        # Update node features based on inputs by multiplying node attributes by \n",
    "        # the weights stored during build.\n",
    "        # Kipf 2016\n",
    "        x = tf.matmul(x, self.kernel)\n",
    "\n",
    "        # Return propagation result\n",
    "        return self.propagate(x=x, a=a)\n",
    "\n",
    "    def message(self, x):\n",
    "        return self.get_j(x)\n",
    "    \n",
    "    def aggregate(self, messages): \n",
    "        # We need to return the result of applying the aggregate function over the messages\n",
    "\n",
    "        # Try to use the mean as aggregate function. We use a scatter mean method for this experiment:\n",
    "        return spektral.layers.ops.scatter_mean(messages, self.index_i, self.n_nodes)\n",
    "\n",
    "    def update(self, embeddings):\n",
    "        return self.activation(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creada la capa, podemos hacer uso de la misma creando un modelo mediante la API funcional de Keras. Para ello, se empieza por configurar algunos parámetros básicos para su funcionamiento:\n",
    "\n",
    "* Ratio de regularización (o *regularization rate*): con el fin de regularizar los contenidos. Se inicia con un valor de `5e-6`.\n",
    "* Ratio de aprendizaje (o *learning rate*) con un valor de 0.2.\n",
    "* Número de epochs de entrenamiento, que son fijadas en 20.\n",
    "* Nivel de paciencia para el early stopping que será usado más abajo en la etapa de entrenamiento.\n",
    "\n",
    "Hecho esto, se extran las características principales de los datos: número de nodos, número de careacterísticas por nodo y número de clases para clasificarlos. Estos datos serán usados para instanciar la capa de paso de mensajes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup for the model\n",
    "l2_regularization_rate = 5e-6\n",
    "learning_rate = 0.2\n",
    "epochs = 400\n",
    "patience = 10\n",
    "\n",
    "# Input parameters\n",
    "number_of_nodes = dataset.n_nodes\n",
    "number_of_node_features = dataset.n_node_features\n",
    "number_of_labels = dataset.n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de definir las entradas. Para ello, se crearán dos tensores:\n",
    "\n",
    "* `adjacency_matrix` con la matriz de adyacencia, que contendrá la matriz de adyacencia y que permitirá saber las conexiones de cada nodo.\n",
    "* `x_input` con las características de cada nodo.\n",
    "\n",
    "Ambas son usadas para definir la capa de salida del modelo, que será construida mediante la clase definida para el MPNNLayer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define input tensors\n",
    "# We define two input tensors: one for the nodes and one for the adjacency matrix\n",
    "from keras.layers import Input\n",
    "adjacency_input = Input(\n",
    "    (number_of_nodes,), sparse=True, dtype=dataset[0].a.dtype,\n",
    "    name='adjacency_matrix_input'\n",
    ")\n",
    "x_input = Input(\n",
    "    shape=(number_of_node_features,),\n",
    "    name='nodes_input'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output layer based on the MPNN layer defined previously as MPNNLayer\n",
    "mpnn_output_layer = MPNNLayer(\n",
    "    number_of_labels, activation=keras.activations.softmax,\n",
    "    kernel_regularizer=keras.regularizers.l2(l2_regularization_rate),\n",
    "    use_bias=False, name='mpnn_layer'\n",
    ")([x_input, adjacency_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mpnn_gcn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " nodes_input (InputLayer)       [(None, 1433)]       0           []                               \n",
      "                                                                                                  \n",
      " adjacency_matrix_input (InputL  [(None, 2708)]      0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " mpnn_layer (MPNNLayer)         (None, 7)            10031       ['nodes_input[0][0]',            \n",
      "                                                                  'adjacency_matrix_input[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,031\n",
      "Trainable params: 10,031\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile model\n",
    "from keras.models import Model\n",
    "model_mpnn = Model(\n",
    "    name='mpnn_gcn',\n",
    "    inputs=[x_input, adjacency_input],\n",
    "    outputs=mpnn_output_layer\n",
    ")\n",
    "model_mpnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "    loss=loss_function,\n",
    "    weighted_metrics=['acc']\n",
    ")\n",
    "model_mpnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 1.9454 - acc: 0.1571 - val_loss: 1.8716 - val_acc: 0.7080\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7827 - acc: 0.9929 - val_loss: 1.7990 - val_acc: 0.7220\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.6255 - acc: 0.9929 - val_loss: 1.7289 - val_acc: 0.7200\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4755 - acc: 0.9929 - val_loss: 1.6616 - val_acc: 0.7220\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3336 - acc: 0.9929 - val_loss: 1.5972 - val_acc: 0.7240\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2009 - acc: 0.9929 - val_loss: 1.5359 - val_acc: 0.7220\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0779 - acc: 0.9929 - val_loss: 1.4778 - val_acc: 0.7280\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9650 - acc: 0.9929 - val_loss: 1.4229 - val_acc: 0.7280\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8623 - acc: 0.9929 - val_loss: 1.3713 - val_acc: 0.7340\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7695 - acc: 0.9929 - val_loss: 1.3231 - val_acc: 0.7400\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6863 - acc: 0.9929 - val_loss: 1.2783 - val_acc: 0.7380\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6121 - acc: 0.9929 - val_loss: 1.2368 - val_acc: 0.7380\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5462 - acc: 0.9929 - val_loss: 1.1986 - val_acc: 0.7360\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4880 - acc: 0.9929 - val_loss: 1.1637 - val_acc: 0.7360\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4366 - acc: 0.9929 - val_loss: 1.1318 - val_acc: 0.7400\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3914 - acc: 0.9929 - val_loss: 1.1028 - val_acc: 0.7440\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3516 - acc: 0.9929 - val_loss: 1.0766 - val_acc: 0.7360\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3166 - acc: 0.9929 - val_loss: 1.0531 - val_acc: 0.7360\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2858 - acc: 0.9929 - val_loss: 1.0319 - val_acc: 0.7360\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2587 - acc: 0.9929 - val_loss: 1.0130 - val_acc: 0.7380\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2348 - acc: 0.9929 - val_loss: 0.9961 - val_acc: 0.7400\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2138 - acc: 0.9929 - val_loss: 0.9810 - val_acc: 0.7360\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1952 - acc: 0.9929 - val_loss: 0.9676 - val_acc: 0.7360\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1787 - acc: 0.9929 - val_loss: 0.9556 - val_acc: 0.7360\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1641 - acc: 0.9929 - val_loss: 0.9450 - val_acc: 0.7360\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1512 - acc: 0.9929 - val_loss: 0.9355 - val_acc: 0.7320\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1396 - acc: 0.9929 - val_loss: 0.9271 - val_acc: 0.7320\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1294 - acc: 0.9929 - val_loss: 0.9196 - val_acc: 0.7300\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1202 - acc: 0.9929 - val_loss: 0.9129 - val_acc: 0.7280\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1119 - acc: 0.9929 - val_loss: 0.9068 - val_acc: 0.7280\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1045 - acc: 0.9929 - val_loss: 0.9015 - val_acc: 0.7260\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0979 - acc: 1.0000 - val_loss: 0.8966 - val_acc: 0.7220\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0919 - acc: 1.0000 - val_loss: 0.8923 - val_acc: 0.7240\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0865 - acc: 1.000 - 0s 95ms/step - loss: 0.0865 - acc: 1.0000 - val_loss: 0.8884 - val_acc: 0.7220\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0816 - acc: 1.0000 - val_loss: 0.8849 - val_acc: 0.7180\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0771 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.7180\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0731 - acc: 1.0000 - val_loss: 0.8789 - val_acc: 0.7180\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0694 - acc: 1.0000 - val_loss: 0.8764 - val_acc: 0.7180\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0660 - acc: 1.0000 - val_loss: 0.8741 - val_acc: 0.7200\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0629 - acc: 1.0000 - val_loss: 0.8721 - val_acc: 0.7200\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0601 - acc: 1.0000 - val_loss: 0.8702 - val_acc: 0.7180\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0575 - acc: 1.0000 - val_loss: 0.8686 - val_acc: 0.7180\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0552 - acc: 1.0000 - val_loss: 0.8671 - val_acc: 0.7180\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.8659 - val_acc: 0.7180\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0509 - acc: 1.0000 - val_loss: 0.8647 - val_acc: 0.7180\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0491 - acc: 1.0000 - val_loss: 0.8638 - val_acc: 0.7180\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.8629 - val_acc: 0.7180\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0457 - acc: 1.0000 - val_loss: 0.8622 - val_acc: 0.7180\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0442 - acc: 1.0000 - val_loss: 0.8616 - val_acc: 0.7200\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0428 - acc: 1.0000 - val_loss: 0.8610 - val_acc: 0.7200\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.8606 - val_acc: 0.7180\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.8603 - val_acc: 0.7180\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0391 - acc: 1.0000 - val_loss: 0.8600 - val_acc: 0.7180\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 0.7200\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.8596 - val_acc: 0.7180\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.7160\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.7160\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0343 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.7160\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0335 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.7160\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.7180\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.8596 - val_acc: 0.7180\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.8597 - val_acc: 0.7180\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 0.7180\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0300 - acc: 1.0000 - val_loss: 0.8599 - val_acc: 0.7180\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.8600 - val_acc: 0.7180\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.8601 - val_acc: 0.7160\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.8603 - val_acc: 0.7160\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.8604 - val_acc: 0.7160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14707b070>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "loader_tr = SingleLoader(dataset, sample_weights=weighted_mask[0])\n",
    "loader_va = SingleLoader(dataset, sample_weights=weighted_mask[1])\n",
    "model_mpnn.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_va.load(),\n",
    "    validation_steps=loader_va.steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "        TensorBoard(get_run_logdir('gcn_spatial'))\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo, se puede evaluar contra el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8306 - acc: 0.7490\n",
      "Test loss: 0.8306456804275513\n",
      "Test accuracy: 0.7490002512931824\n"
     ]
    }
   ],
   "source": [
    "loader_te = SingleLoader(dataset, sample_weights=weighted_mask[2])\n",
    "results = model_mpnn.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "\n",
    "print(f'Test loss: {results[0]}')\n",
    "print(f'Test accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 3: clasificación de nodos mediante información de nodos\n",
    "\n",
    "En este caso, en lugar de utilizar la información estrutural del grafo, se hará uso solo de las características de los nodos.\n",
    "\n",
    "El primer paso será construir una estructura de datos que nos permita trabajar con un modelo que no esté diseñado para operar sobre grafos. Para ello, se extraerán las características de cada observación de los datos de origen y no se usarán sus enlaces. Con todo, el objetivo es medir el nivel de precisión a la hora de clasificar sin utilizar la estructura generado mediante las relaciones entre nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: X (140, 1433), y (140, 7), from a source of 140 samples\n",
      "Validation: X (500, 1433), y (500, 7), from a source of 500 samples\n",
      "Test: X (1000, 1433), y (1000, 7), from a source of 1000 samples\n"
     ]
    }
   ],
   "source": [
    "# Extract train, validation and test features and labels\n",
    "X_train = dataset[0].x[np.array(dataset.mask_tr)]\n",
    "y_train = dataset[0].y[np.array(dataset.mask_tr)]\n",
    "X_validation = dataset[0].x[np.array(dataset.mask_va)]\n",
    "y_validation = dataset[0].y[np.array(dataset.mask_va)]\n",
    "X_test = dataset[0].x[np.array(dataset.mask_te)]\n",
    "y_test = dataset[0].y[np.array(dataset.mask_te)]\n",
    "\n",
    "print(f'Training: X {X_train.shape}, y {y_train.shape}, from a source of {np.sum(dataset.mask_tr)} samples')\n",
    "print(f'Validation: X {X_validation.shape}, y {y_validation.shape}, from a source of {np.sum(dataset.mask_va)} samples')\n",
    "print(f'Test: X {X_test.shape}, y {y_test.shape}, from a source of {np.sum(dataset.mask_te)} samples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han obtenido los diferentes subconjuntos de datos:\n",
    "\n",
    "* Conjunto de entrenamiento, formado por las observaciones `X_train` y las categorías de cada una de ellas, `y_train`.\n",
    "* Conjunto de validación, formado por las observaciones `X_validation` y las categorías de cada una de ellas, `y_validation`.\n",
    "* Conjunto de pruebas, formado por las observaciones `X_test` y las categorías de cada una de ellas, `y_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"non_gnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " nodes_input (Flatten)       (None, 1433)              0         \n",
      "                                                                 \n",
      " hidden_dense (Dense)        (None, 100)               143400    \n",
      "                                                                 \n",
      " output (Dense)              (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144,107\n",
      "Trainable params: 144,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequential_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=X_train[0].shape, name='nodes_input'),\n",
    "    keras.layers.Dense(100, activation=keras.activations.relu, name='hidden_dense'),\n",
    "    keras.layers.Dense(7, activation=keras.activations.relu, name='output')\n",
    "], name='non_gnn')\n",
    "sequential_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras la definición, se puede pasar a compilar y entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 205.5530 - acc: 0.1143 - val_loss: 127.3735 - val_acc: 0.1220\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 100.9140 - acc: 0.4357 - val_loss: 77.6523 - val_acc: 0.1900\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 68.2276 - acc: 0.5500 - val_loss: 61.4182 - val_acc: 0.2660\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60.1177 - acc: 0.7429 - val_loss: 58.6055 - val_acc: 0.2800\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43.9569 - acc: 0.8571 - val_loss: 59.4575 - val_acc: 0.2900\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40.3762 - acc: 0.8643 - val_loss: 59.1309 - val_acc: 0.2980\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34.1753 - acc: 0.9000 - val_loss: 61.2491 - val_acc: 0.3000\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28.9551 - acc: 0.9500 - val_loss: 70.6831 - val_acc: 0.3100\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.8924 - acc: 0.9786 - val_loss: 92.7602 - val_acc: 0.3260\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.4147 - acc: 0.9857 - val_loss: 132.7101 - val_acc: 0.3400\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5111 - acc: 0.9929 - val_loss: nan - val_acc: 0.3460\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5771 - acc: 1.0000 - val_loss: nan - val_acc: 0.3500\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.7735 - acc: 1.0000 - val_loss: nan - val_acc: 0.3220\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1800 - acc: 1.0000 - val_loss: nan - val_acc: 0.2800\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 27ms/step - loss: nan - acc: 0.7286 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 25ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 23ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 23ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1489e2f40>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=CategoricalCrossentropy(reduction=reduction_function), # Loss function to be used.\n",
    "    weighted_metrics=['acc']\n",
    ")\n",
    "\n",
    "sequential_model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20,  restore_best_weights=True), # Early stopping callback\n",
    "        TensorBoard(get_run_logdir('non_gnn'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 79.8807 - acc: 0.2800\n",
      "Test loss: 79.88072204589844\n",
      "Test accuracy: 0.2800000011920929\n"
     ]
    }
   ],
   "source": [
    "results = sequential_model.evaluate(X_test, y_test, batch_size=42)\n",
    "\n",
    "print(f'Test loss: {results[0]}')\n",
    "print(f'Test accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 4: predicción de enlaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter,Embedding\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter_mean, scatter, scatter_add, scatter_max\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn import GCNConv \n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from WalkPooling.src.model import LinkPred, WalkPooling, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ratio: 0.18463810930576072\n",
      "Test ratio: 0.051698670605613\n",
      "Learning rate: 0.0005\n"
     ]
    }
   ],
   "source": [
    "# Link prediction message passing model settings\n",
    "number_of_heads_in_attention_link_encoder = 2\n",
    "walk_length = 2 # Number of learning iterations based on messages passing, called \"walk length\" (#TODO referenciar paper)\n",
    "use_mse = False\n",
    "practical_neg_sample = False\n",
    "\n",
    "# Copy validation and test ratios from experiments performed using Spektral\n",
    "val_ratio = np.sum(dataset.mask_va)/number_of_nodes\n",
    "test_ratio = np.sum(dataset.mask_tr)/number_of_nodes\n",
    "\n",
    "class MyDict(dict):\n",
    "    pass\n",
    "\n",
    "args = MyDict()\n",
    "args.data_name = 'cora'\n",
    "args.seed = 1\n",
    "args.use_splitted = False\n",
    "args.practical_neg_sample = True\n",
    "args.observe_val_and_injection = False\n",
    "args.init_attribute=None\n",
    "args.lr = 0.0005 # learning rate\n",
    "args.val_ratio = 0.2\n",
    "args.test_ratio = 0.2\n",
    "args.init_representation = None\n",
    "args.num_hops = 3\n",
    "args.max_nodes_per_hop = 100\n",
    "args.drnl = False\n",
    "args.batch_size = 32\n",
    "args.weight_decay = 0\n",
    "args.epoch_num = 10\n",
    "\n",
    "\n",
    "# Get device definition, by default cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instance LinkPred model\n",
    "model = LinkPred(\n",
    "    in_channels=number_of_node_features, # Number of nodes used as input data\n",
    "    hidden_channels=number_of_labels, # Number of labels used as output data\n",
    "    heads=number_of_heads_in_attention_link_encoder, # Number of attention heads\n",
    "    walk_len=walk_length, \n",
    "    # drnl = args.drnl,\n",
    "    # z_max = z_max, \n",
    "    MSE=use_mse\n",
    ").to(device)\n",
    "\n",
    "# Select optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Prompt settings to notebook\n",
    "print(f'Validation ratio: {val_ratio}')\n",
    "print(f'Test ratio: {test_ratio}')\n",
    "print(f'Learning rate: {args.lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data: cora\n",
      "Train_link: 6336  Val_link: 2110  Test_link: 2110\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "from WalkPooling.src.utils import prepare_data\n",
    "train_loader, val_loader, test_loader, feature_results = prepare_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(loader,epoch):\n",
    "    model.train()\n",
    "    loss_epoch=0\n",
    "    for data in tqdm(loader,desc=\"train\"):  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        label= data.label\n",
    "        out = model(data.x, data.edge_index, data.edge_mask, data.batch, data.z)\n",
    "        torch.cuda.empty_cache()\n",
    "        loss = criterion(out.view(-1), label)  \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        loss_epoch=loss_epoch+loss.item()\n",
    "    return loss_epoch/len(loader)\n",
    "\n",
    "\n",
    "def test(loader,data_type='test'):\n",
    "    model.eval()\n",
    "    scores = torch.tensor([])\n",
    "    labels = torch.tensor([])\n",
    "    loss_total=0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader,desc='test:'+data_type):  # Iterate in batches over the training/test dataset.\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.edge_mask, data.batch, data.z)\n",
    "            loss = criterion(out.view(-1), data.label)\n",
    "            out = out.cpu().clone().detach()\n",
    "            scores = torch.cat((scores,out),dim = 0)\n",
    "            labels = torch.cat((labels,data.label.view(-1,1).cpu().clone().detach()),dim = 0)\n",
    "        scores = scores.cpu().clone().detach().numpy()\n",
    "        labels = labels.cpu().clone().detach().numpy()\n",
    "        loss_total=loss_total+loss.item()\n",
    "        return roc_auc_score(labels, scores), average_precision_score(labels, scores),loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 198/198 [01:06<00:00,  2.97it/s]\n",
      "test:val: 100%|██████████| 66/66 [00:11<00:00,  5.91it/s]\n",
      "test:test: 100%|██████████| 66/66 [00:08<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001\t Loss: 0.2427\n",
      "Validation accuracy: 0.8396\tValidation loss: 0.1765\n",
      "Test accuracy: 0.8261\tTest loss: 0.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 198/198 [01:00<00:00,  3.25it/s]\n",
      "test:val: 100%|██████████| 66/66 [00:09<00:00,  6.60it/s]\n",
      "test:test:  36%|███▋      | 24/66 [00:04<00:07,  5.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ql/3w89m27d7mn4c5fdsnrhrrp00000gn/T/ipykernel_70453/2695061273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Log performance metrics into TensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ql/3w89m27d7mn4c5fdsnrhrrp00000gn/T/ipykernel_70453/3993885772.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader, data_type)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test:'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Iterate in batches over the training/test dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vscode-projects/uoc-tfg-gnn/WalkPooling/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_mask, batch, z)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#Walk Pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mfeature_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vscode-projects/uoc-tfg-gnn/WalkPooling/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_mask, batch)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mx_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mx_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;31m# returning probabilities around i + j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msegment_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    386\u001b[0m                            reduce=self.aggr)\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \"\"\"\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mul'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_sum\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare TensorBoard to receive data from this training\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter(log_dir=get_run_logdir('mpnn_walkpooling'))\n",
    "\n",
    "# Iterate each epoch to train the model. Send performance metrics to TensorBoard\n",
    "for epoch in range(1, args.epoch_num + 1):\n",
    "    epoch_loss = train(train_loader, epoch)\n",
    "    _, val_ap, val_loss = test(val_loader, data_type='val')\n",
    "    _, test_ap, test_loss = test(test_loader, data_type='test')\n",
    "\n",
    "    # Log performance metrics into TensorBoard\n",
    "    tb.add_scalar('epoch_loss', epoch_loss, epoch) # Log epoch loss\n",
    "    # tb.add_scalar('epoch_acc', val_ap, epoch) # Log epoch accuracy\n",
    "    tb.add_scalar('validation_loss', val_loss, epoch) # Log epoch validation loss\n",
    "    tb.add_scalar('validation_acc', val_ap, epoch) # Log epoch validation accuracy\n",
    "    tb.add_scalar('test_loss', test_ap, epoch) # Log test loss\n",
    "    tb.add_scalar('test_acc', test_loss, epoch) # Log test accuracy\n",
    "\n",
    "    # Prompt to notebook\n",
    "    print(f'Epoch: {epoch:03d}\\t Loss: {epoch_loss:.4f}\\nValidation accuracy: {val_ap:.4f}\\tValidation loss: {val_loss:.4f}\\nTest accuracy: {test_ap:.4f}\\tTest loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0080289cbe72122e4cc1d387721a77267b793dcb0222027115d0fe70e838b1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('uoc-tfg-gnn': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
