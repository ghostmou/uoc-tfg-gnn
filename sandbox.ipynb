{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFG: Alfonso Moure\n",
    "\n",
    "Este fichero contiene un borrador del proyecto TFG de Alfonso Moure, donde se exploran diferentes técnicas para el trabajo con redes neuronales gráficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando los módulos necesarios\n",
    "\n",
    "Como primer paso, se va a proceder a instalar los módulos necesarios para las pruebas:\n",
    "\n",
    "* [numpy](https://numpy.org/), para poder realizar las operaciones necesarias sobre los datos.\n",
    "* [TensorFlow](https://www.tensorflow.org/), como librería principal para ejecutar los distintos algoritmos de aprendizaje computacional a los que será necesario recurrir.\n",
    "* [Spektral](https://graphneural.network/), una cómoda librería y colección de sets de datos que permite trabajar de manera cómoda con redes neuronales gráficas.\n",
    "\n",
    "Una vez instalados, se procede a imporarlos. Aunque se incluye la descripción del fichero requierements.txt con el proyecto, se proceden a importar desde el notebook para aportar una mayor claridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.19.5)\n",
      "Requirement already satisfied: tensorflow in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: spektral in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: joblib in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (4.62.3)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.0.1)\n",
      "Requirement already satisfied: requests in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.26.0)\n",
      "Requirement already satisfied: lxml in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (4.6.4)\n",
      "Requirement already satisfied: scipy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.7.2)\n",
      "Requirement already satisfied: pandas in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.3.4)\n",
      "Requirement already satisfied: networkx in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.6.3)\n",
      "Requirement already satisfied: numpy<1.20 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.37.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.13.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (12.0.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (4.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.42.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.22.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->spektral) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->spektral) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (1.26.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scikit-learn->spektral) (3.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (57.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required modules\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import downloaded modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras # To be able to use Keras more easily from the code\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, se crea un fichero de configuración para Spektral en el directorio raíz del usuario, tal y como se indica en la configuración de dicho módulo. Se crea en la ruta `~/.spektral/config.json` y se guarda el siguiente contenido:\n",
    "\n",
    "```\n",
    "{\n",
    "        \"dataset_folder\": \"/Users/ghostmou/vscode-projects/uoc-tfg-gnn/spektraldata\"\n",
    "}\n",
    "```\n",
    "\n",
    "Esto indica a Spektral que se desea guardar la información descargada para los juegos de datos que van a ser usados en la ruta indicada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del juego de datos para las pruebas\n",
    "\n",
    "Como se indica en la memoria de proyecto, se hará uso del juego de datos conocido como CORA. Gracias a Spektral, es sencillo descargar este juego de datos y sus distintas estructuras ya preparadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cora dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download CORA dataset and its different members\n",
    "dataset = spektral.datasets.citation.Citation(\n",
    "    'cora', \n",
    "    random_split=False, # split randomly: 20 nodes per class for training, 30 nodes \n",
    "        # per class for validation; or \"Planetoid\" (Yang et al. 2016)\n",
    "    normalize_x=False,  # normalize the features\n",
    "    dtype=np.float32 # numpy data type for the graph data\n",
    "    )\n",
    "dataset.graphs[0]\n",
    "\n",
    "# Also load a list of labels as names, justo to be able to use it\n",
    "label_names = ['Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el conjunto de datos descargado, podemos ver que el resumen nos muestra que se ha descargado un grafo con las siguientes características:\n",
    "\n",
    "* 2708 nodos o vértices forman el grafo.\n",
    "* 1433 atributos de nodo.\n",
    "* 0 atributos de relación, es decir, es un nodo cuyas aristas no contienen información.\n",
    "* 7 clases. En base a la definición del juego de datos, sabemos que los vértices se clasifican en dicho número de grupos. Sin embargo, como se explica en la memoria de proyecto, también es posible hacer uso de GNNs para clasificar grafos, por lo que Spektral nos permite trabajar con dos tipos de etiquetas: de nodo y de grafo.\n",
    "\n",
    "Por otro lado, el conjunto de datos recuperado ya viene dividido en tres grupos de muestras:\n",
    "\n",
    "* Muestras de entrenamiento, que aparecen marcadas mediante enmascaramiento con la estructura `mask_tr`.\n",
    "* Muestras de validación, que hacen lo propio mediante `mask_va`.\n",
    "* Muestras de prueba o test, enmascaradas con `mask_te`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 140\n",
      "Validation samples: 500\n",
      "Test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Training samples: {np.sum(dataset.mask_tr)}')\n",
    "print(f'Validation samples: {np.sum(dataset.mask_va)}')\n",
    "print(f'Test samples: {np.sum(dataset.mask_te)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación TensorBoard para seguimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder con la implementación de los ejemplos, se prepara un entorno basado en TensorBoard para poder visualizar y analizar la ejecución  y sus resultados de manera visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorBoard callback to be able to use it in all the code samples\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Prepare placement for the logs\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "def get_run_logdir(model_in_use):\n",
    "    import time\n",
    "    run_id = time.strftime(f'run_{model_in_use}_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de pruebas\n",
    "\n",
    "A continuación, se va a trabajar en la implementación de varios modelos diferentes de ConvGNN para explicar su funcionamiento:\n",
    "\n",
    "* ConvGNN espectral, con un ejemplo de clasificación de nodos.\n",
    "* ConvGNN espacial con paso de mensajes o MPNN, con un ejemplo de clasificación de nodos.\n",
    "\n",
    "Cada apartado irá rematado con un estudio de precisión. Todos los casos serán ejecutados mediante GridSearch para intentar encontrar el resultado más óptimo bajo las condiciones actuales. Además, se extraerá información gráfica mediante TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 1: ConvGNN espectral\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede verse que se cuenta con 140 muestras de entrenamiento, 500 de validación y 1000 de test.\n",
    "\n",
    "Dado que este enmascaramiento se lleva a cabo mediante datos binarios (verdadero o falso; incluido o excluido de cada subconjunto, respectivamente), es preciso transformar estos valores en pesos que puedan ser usados durante el proceso de aprendizaje: sabemos que las CNN espestrales no hacen uso de los features de nodos y vértices para su toma de decisiones.\n",
    "\n",
    "Para ello, se crea una función que convierte estas colecciones en una media de peso de los valores de los nodos.\n",
    "\n",
    "**ESTE BLOQUE REQUIERE REVISIÓN DESDE MIS NOTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighed_mask = [\n",
    "    mask.astype(np.float32) / np.count_nonzero(mask)\n",
    "    for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, cada vértice de cada colección de muestras tendrá asignado un peso igual al del resto de su conjunto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples weight: 0.0071428571827709675\n",
      "Validation samples weight: 0.0020000000949949026\n",
      "Test samples weight: 0.0010000001639127731\n"
     ]
    }
   ],
   "source": [
    "print(f'Training samples weight: {np.nanmean(np.where(weighed_mask[0] > 0, weighed_mask[0],np.nan), 0)}')\n",
    "print(f'Validation samples weight: {np.nanmean(np.where(weighed_mask[1] > 0, weighed_mask[1],np.nan), 0)}')\n",
    "print(f'Test samples weight: {np.nanmean(np.where(weighed_mask[2] > 0, weighed_mask[2],np.nan), 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparados los datos, se puede proceder a definir el modelo. Para ello, se hará uso del existente GCN procedente de Spektral (`spektral.models.gcn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from spektral.models.gcn import GCN\n",
    "\n",
    "# Import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Import loss function from Keras\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Set initial configuration\n",
    "learning_rate = 0.01\n",
    "reduction_function = 'sum'\n",
    "\n",
    "# Create model from Spektral\n",
    "model_gcn = GCN(n_labels=dataset.n_labels, n_input_channels=dataset.n_node_features)\n",
    "\n",
    "# Compile loaded model\n",
    "model_gcn.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate), # Set optimizer as Adam with a learning rate of 0.01\n",
    "    loss=CategoricalCrossentropy(reduction=reduction_function), # Loss function to be used.\n",
    "    weighted_metrics=['acc'] # Metrics to be evaluated and weighted during training (Keras doc: https://keras.io/api/models/model_training_apis/)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos el modelo creado y compilado, es posible proceder con su entrenamiento. Para ello, se empieza por crear los cargadores (*Loaders*) de Spektral para entrenamiento y validación, básicos para las tareas de entrenamiento. Dentro de Spektral, los *loaders* son usados para generar lotes de subgrafos para poder hacer sucesivas pasadas de entrenamiento en la red convolucional en uso. \n",
    "\n",
    "Gracias a que Spektral está diseñado para trabajar con Keras, la clase `Loader` incluye un método `load` que puede ser usado en para llamar al método `fit` del modelo.\n",
    "\n",
    "Puesto que el conjunto de datos incluye un solo grafo, es posible hacer uso del cargador `SingleLoader`, diseñado para trabajar con este tipo de estructuras de grafo único. Puede ser configurado mediante los siguientes parámetros pasados durante su inicialización:\n",
    "\n",
    "* `dataset`, que incluye, como puede deducirse, la estructura de datos.\n",
    "* `epochs`, con la cantidad de **epochs** que van a ser usados durante la fase de entrenamiento.\n",
    "* `shuffle`, para indicar si se desea barajar los contenidos del conjunto de datos tras cada epoch.\n",
    "* `sample_weights`, que podrá ser usado para indicar el peso de cada observación y que, en caso de ser usado en la inicialización, será devuelto en cada paso de entrenamiento. Esta es la estructura que hemos generado con anterioridad para cada subconjunto de entrenamiento, pruebas y validación en base a las estructuras binarias originales. Así, se usará un vector de pesos diferente según el cargador que estemos preparando.\n",
    "\n",
    "Puesto que el siguiente paso es llevar a cabo el entrenamiento del modelo, se prepararán los cargadores de los datos de entrenamiento y validación mediante `SingleLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data.loaders import SingleLoader\n",
    "loader_training = SingleLoader(dataset, sample_weights=weighed_mask[0])\n",
    "loader_validation = SingleLoader(dataset, sample_weights=weighed_mask[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los cargadores listos, es posible proceder a entrenar el modelo mediante la función `fit`. A modo de prueba, se hará con un total de `50` epochs. Además, se incorpora un callback de Keras, `EarlyStopping`, que permitirá detener el entrenamiento cuando el proceso detecte que no se está obteniendo una mejora sustancial.\n",
    "\n",
    "Como se mencionó más arriba, se incorpora también un callback `TensorBoard` para poder analizar las pruebas. Sus resultados serán accesibles mediante el siguiente comando de consola:\n",
    "\n",
    "```shell\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 4.6862 - acc: 0.1571 - val_loss: 2.1933 - val_acc: 0.2900\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0274 - acc: 0.3571 - val_loss: 2.1583 - val_acc: 0.2460\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7115 - acc: 0.3786 - val_loss: 1.8865 - val_acc: 0.3180\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.7389 - acc: 0.4000 - val_loss: 1.4801 - val_acc: 0.4700\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2595 - acc: 0.6071 - val_loss: 1.3815 - val_acc: 0.5560\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3172 - acc: 0.5429 - val_loss: 1.3411 - val_acc: 0.5940\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2455 - acc: 0.5357 - val_loss: 1.3283 - val_acc: 0.5960\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2088 - acc: 0.6429 - val_loss: 1.3057 - val_acc: 0.5960\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0693 - acc: 0.6429 - val_loss: 1.2759 - val_acc: 0.6140\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0881 - acc: 0.7214 - val_loss: 1.2548 - val_acc: 0.6420\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9238 - acc: 0.7714 - val_loss: 1.2379 - val_acc: 0.6420\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9527 - acc: 0.7286 - val_loss: 1.2291 - val_acc: 0.6600\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9242 - acc: 0.7714 - val_loss: 1.3156 - val_acc: 0.6120\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7786 - acc: 0.7857 - val_loss: 1.5162 - val_acc: 0.6060\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8261 - acc: 0.7071 - val_loss: 1.5506 - val_acc: 0.6040\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3384 - acc: 0.6714 - val_loss: 1.4852 - val_acc: 0.6020\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7236 - acc: 0.7857 - val_loss: 1.4466 - val_acc: 0.6140\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7782 - acc: 0.6929 - val_loss: 1.4368 - val_acc: 0.6120\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7683 - acc: 0.7357 - val_loss: 1.4337 - val_acc: 0.5960\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6532 - acc: 0.7643 - val_loss: 1.4791 - val_acc: 0.6020\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6807 - acc: 0.7571 - val_loss: 1.5124 - val_acc: 0.6000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6367 - acc: 0.7857 - val_loss: 1.5400 - val_acc: 0.6100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14915aaf0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model_gcn.fit(\n",
    "    loader_training.load(),\n",
    "    steps_per_epoch=loader_training.steps_per_epoch,\n",
    "    validation_data=loader_validation.load(),\n",
    "    validation_steps=loader_validation.steps_per_epoch,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10,  restore_best_weights=True), # Early stopping callback\n",
    "        TensorBoard(get_run_logdir('gcn_spectral'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho este entrenamiento, se puede proceder a evaluar su eficacia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3889 - acc: 0.6890\n",
      "Loss: 1.388916015625\n",
      "Accuracy: 0.6890002489089966\n"
     ]
    }
   ],
   "source": [
    "loader_test = SingleLoader(dataset, sample_weights=weighed_mask[2])\n",
    "results = model_gcn.evaluate(\n",
    "    loader_test.load(), \n",
    "    steps=loader_test.steps_per_epoch\n",
    ")\n",
    "print(f'Loss: {results[0]}')\n",
    "print(f'Accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 2: ConvGNN espacial mediante paso de mensajes: MPNN\n",
    "\n",
    "En el ejemplo anterior se ha basado el aprendizaje y la clasificación en la estructura espectral de los datos cargados, es decir, en la estructura de la matriz de adyacencia. Sin embargo, tal y como se explica en la memoria de proyecto, esta aproximación puede ser pobre para escenarios donde las relaciones (aristas) entre entidades (vértices) del grafo tienen un significado o importancia diferente, o cuando el contexto de un nodo, construido mediante los atributos de sus vecinos, es importante para la clasificación.\n",
    "\n",
    "Para poder preparar este ejemplo, se hará uso de la clase `MessagePassing` de Spektral, que ofrece una API ya preparada para configurar la función de activación y personalizar el comportamiento para distintos juegos de datos. Así, será preciso personalizar:\n",
    "\n",
    "* Función para la construcción del mensaje pasado entre dos vértices vía la arista que los une. Es conocida como `message` dentro de la API de Spektral.\n",
    "* Selección de la función de agregación de los mensajes pasados desde cada arista a cada nodo: suma, media, etc. Aparece definida como `aggregate`.\n",
    "\n",
    "Puesto que las GNN basadas en paso de mensajes requieren sucesivas iteraciones que permitan propagar los mensajes a niveles cada vez más lejanos, la función `propagate` lo ejecuta y computa los atributos de cada nodo tras pasar los mensajes de todas las aristas del grafo y computar la correspondiente función de agregación.\n",
    "\n",
    "Puesto que Spektral está construido sobre Keras, es preciso, además, implementar algunos de los métodos heredados de la clase `Layer` para definir la capa gráfica espacial:\n",
    "\n",
    "* `__init__`, donde se define la función de activación, se pasan el resto de hiperparámetros estándar y se guarda el dato del tamaño de la salida, que será usado más adelante.\n",
    "* `build`, cuya misión es la de inicializar los pesos de la capa mediante la llamada a `add_weight` y asignar el tamaño que tendrá la matriz utilizada para almacenar los pesos dentro de la capa. La matriz de pesos tendrá tantas filas como la entrada y columnas como la salida.\n",
    "* `call` es el método encargado de ejecutar los cálculos de la capa. Puesto que estamos hablando de paso de mensajes, la salida de la capa será función de las característica de los nodos de entrada y los pesos de la capa. Al final de la misma, en lugar de llamar a la función de activación, se llama a `propagate`, un método disponible dentro de `MessagePassing` encargado de realizar la propagación de los mensajes de cada nodo a sus vecinos.\n",
    "\n",
    "A estos métodos estándar, se incorporan otros de la propia API de Spektral, especializados en el trabajo con redes gráficas:\n",
    "\n",
    "* `message`, encargado de componer el mensaje que será pasado entre los nodos. En este ejemplo se hace uso de la información de los nodos vecinos, accesibles mediante `get_j`.\n",
    "* `aggregate`, con el cometido de definir la función de agregación para los mensajes del vecindario. Aquí se hace uso de la media de todos los mensajes del vecindario, aunque una posible mejora del modelo podría ser el uso de hiperparámetros para encontrar la que mejores reusltados pueda dar. Esta opción es posible desde el propio constructor.\n",
    "* `update` donde, ahora sí, se hace uso de la función de activaciónn apra actualizar la matriz de pesos.\n",
    "\n",
    "Con todo, se empieza creando la clase MPNNLayer como herencia `MessagePassing` para preparar la personalización de los citados métodos y definir la capa de paso de mensajes del modelo a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import MessagePassing\n",
    "\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, n_out, activation, **kwargs):\n",
    "        # Initialize message passing layer with the activation function chosen when creating the model\n",
    "        super().__init__(activation=activation, **kwargs)\n",
    "        self.n_out = n_out\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(batch_input_shape[0][-1], self.n_out)\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "\n",
    "        # Update node features based on inputs by multiplying node attributes by \n",
    "        # the weights stored during build.\n",
    "        # Kipf 2016\n",
    "        x = tf.matmul(x, self.kernel)\n",
    "\n",
    "        # Return propagation result\n",
    "        return self.propagate(x=x, a=a)\n",
    "\n",
    "    def message(self, x):\n",
    "        return self.get_j(x)\n",
    "    \n",
    "    def aggregate(self, messages): \n",
    "        # We need to return the result of applying the aggregate function over the messages\n",
    "\n",
    "        # Try to use the mean as aggregate function. We use a scatter mean method for this experiment:\n",
    "        return spektral.layers.ops.scatter_mean(messages, self.index_i, self.n_nodes)\n",
    "\n",
    "    def update(self, embeddings):\n",
    "        return self.activation(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creada la capa, podemos hacer uso de la misma creando un modelo mediante la API funcional de Keras. Para ello, se empieza por configurar algunos parámetros básicos para su funcionamiento:\n",
    "\n",
    "* Ratio de regularización (o *regularization rate*): con el fin de regularizar los contenidos. Se inicia con un valor de `5e-6`.\n",
    "* Ratio de aprendizaje (o *learning rate*) con un valor de 0.2.\n",
    "* Número de epochs de entrenamiento, que son fijadas en 20.\n",
    "* Nivel de paciencia para el early stopping que será usado más abajo en la etapa de entrenamiento.\n",
    "\n",
    "Hecho esto, se extran las características principales de los datos: número de nodos, número de careacterísticas por nodo y número de clases para clasificarlos. Estos datos serán usados para instanciar la capa de paso de mensajes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup for the model\n",
    "l2_regularization_rate = 5e-6\n",
    "learning_rate = 0.2\n",
    "epochs = 20\n",
    "patience = 10\n",
    "\n",
    "# Input parameters\n",
    "number_of_nodes = dataset.n_nodes\n",
    "number_of_node_features = dataset.n_node_features\n",
    "number_of_labels = dataset.n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de definir las entradas. Para ello, se crearán dos tensores:\n",
    "\n",
    "* `adjacency_matrix` con la matriz de adyacencia, que contendrá la matriz de adyacencia y que permitirá saber las conexiones de cada nodo.\n",
    "* `x_input` con las características de cada nodo.\n",
    "\n",
    "Ambas son usadas para definir la capa de salida del modelo, que será construida mediante la clase definida para el MPNNLayer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define input tensors\n",
    "# We define two input tensors: one for the nodes and one for the adjacency matrix\n",
    "from keras.layers import Input\n",
    "adjacency_input = Input(\n",
    "    (number_of_nodes,), sparse=True, dtype=dataset[0].a.dtype,\n",
    "    name='adjacency_matrix_input'\n",
    ")\n",
    "x_input = Input(\n",
    "    shape=(number_of_node_features,),\n",
    "    name='nodes_input'\n",
    ")\n",
    "\n",
    "# Define output layer based on the MPNN layer defined previously as MPNNLayer\n",
    "mpnn_output_layer = MPNNLayer(\n",
    "    number_of_labels, activation=keras.activations.softmax,\n",
    "    kernel_regularizer=keras.regularizers.l2(l2_regularization_rate),\n",
    "    use_bias=False, name='mpnn_layer'\n",
    ")([x_input, adjacency_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante una herencia sonbre `keras.models.Model` se puede definir un modelo que tendrá:\n",
    "\n",
    "* Tendrá dos entradas formadas por las dos variables definidas con anterioridad: los datos de cada nodo en `x_input` y la matriz de adyacencia que los relaciona entre sí en `adjacency_matrix`.\n",
    "* La salida será la capa creada en el paso anterior, que ha sido denominada como `mpnn_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " nodes_input (InputLayer)       [(None, 1433)]       0           []                               \n",
      "                                                                                                  \n",
      " adjacency_matrix_input (InputL  [(None, 2708)]      0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " mpnn_layer (MPNNLayer)         (None, 7)            10031       ['nodes_input[0][0]',            \n",
      "                                                                  'adjacency_matrix_input[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,031\n",
      "Trainable params: 10,031\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build and compile model\n",
    "from keras.models import Model\n",
    "model_mpnn = Model(\n",
    "    inputs=[x_input, adjacency_input],\n",
    "    outputs=mpnn_output_layer\n",
    ")\n",
    "model_mpnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    weighted_metrics=['acc']\n",
    ")\n",
    "model_mpnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el resumen impreso del modelo pueden verse las dos capas de entrada descritas, que sirven como entrada para la capa de paso de mensajes. A ellas se conecta la capa de paso de mensajes.\n",
    "\n",
    "Construido el modelo, puede ser entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2247 - val_acc: 0.6500\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.4587e-04 - acc: 1.0000 - val_loss: 0.2072 - val_acc: 0.6800\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1099e-04 - acc: 1.0000 - val_loss: 0.2004 - val_acc: 0.7020\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1606e-04 - acc: 1.0000 - val_loss: 0.2014 - val_acc: 0.7000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.3926e-05 - acc: 1.0000 - val_loss: 0.2059 - val_acc: 0.6880\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.8682e-05 - acc: 1.0000 - val_loss: 0.2119 - val_acc: 0.6940\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1930e-05 - acc: 1.0000 - val_loss: 0.2185 - val_acc: 0.6880\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1016e-05 - acc: 1.0000 - val_loss: 0.2253 - val_acc: 0.6880\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4156e-05 - acc: 1.0000 - val_loss: 0.2321 - val_acc: 0.6900\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.9013e-06 - acc: 1.0000 - val_loss: 0.2387 - val_acc: 0.6840\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.2136e-06 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.6860\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.4547e-06 - acc: 1.0000 - val_loss: 0.2509 - val_acc: 0.6880\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.2560e-06 - acc: 1.0000 - val_loss: 0.2565 - val_acc: 0.6900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1491e7fa0>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "loader_tr = SingleLoader(dataset, sample_weights=dataset.mask_tr)\n",
    "loader_va = SingleLoader(dataset, sample_weights=dataset.mask_va)\n",
    "model_mpnn.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_va.load(),\n",
    "    validation_steps=loader_va.steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenado, podemos evaluar el modelo frente al conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/training.py\", line 1366, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/training.py\", line 1356, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/training.py\", line 1349, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/training.py\", line 1303, in test_step\n        y_pred = self(x, training=False)\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"sequential_16\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(2708, 1433) dtype=float32>, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x1495b44f0>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ql/3w89m27d7mn4c5fdsnrhrrp00000gn/T/ipykernel_25660/488435632.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloader_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done.\\n\"\u001b[0m \u001b[0;34m\"Test loss: {}\\n\"\u001b[0m \u001b[0;34m\"Test accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/training.py\", line 1366, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/training.py\", line 1356, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/training.py\", line 1349, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/training.py\", line 1303, in test_step\n        y_pred = self(x, training=False)\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"sequential_16\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(2708, 1433) dtype=float32>, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x1495b44f0>]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(\"Evaluating model.\")\n",
    "loader_te = SingleLoader(dataset, sample_weights=dataset.mask_te)\n",
    "eval_results = model_mpnn.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 3: clasificación de nodos mediante CNN sin uso de estructura gráfica\n",
    "\n",
    "El primer paso será construir una estructura de datos que nos permita trabajar con un modelo que no esté diseñado para operar sobre grafos. Para ello, se extraerán las características de cada observación de los datos de origen y no se usarán sus enlaces. Con todo, el objetivo es medir el nivel de precisión a la hora de clasificar sin utilizar la estructura generado mediante las relaciones entre nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: X (140, 1433), y (140, 7), from a source of 140 samples\n",
      "Validation: X (500, 1433), y (500, 7), from a source of 500 samples\n",
      "Test: X (1000, 1433), y (1000, 7), from a source of 1000 samples\n"
     ]
    }
   ],
   "source": [
    "# Extract train, validation and test features and labels\n",
    "X_train = dataset[0].x[np.array(dataset.mask_tr)]\n",
    "y_train = dataset[0].y[np.array(dataset.mask_tr)]\n",
    "X_validation = dataset[0].x[np.array(dataset.mask_va)]\n",
    "y_validation = dataset[0].y[np.array(dataset.mask_va)]\n",
    "X_test = dataset[0].x[np.array(dataset.mask_te)]\n",
    "y_test = dataset[0].y[np.array(dataset.mask_te)]\n",
    "\n",
    "print(f'Training: X {X_train.shape}, y {y_train.shape}, from a source of {np.sum(dataset.mask_tr)} samples')\n",
    "print(f'Validation: X {X_validation.shape}, y {y_validation.shape}, from a source of {np.sum(dataset.mask_va)} samples')\n",
    "print(f'Test: X {X_test.shape}, y {y_test.shape}, from a source of {np.sum(dataset.mask_te)} samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - 1s 54ms/step - loss: 275.7899 - acc: 0.2214 - val_loss: 183.8702 - val_acc: 0.3520\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 180.6099 - acc: 0.5214 - val_loss: 162.0301 - val_acc: 0.3980\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 154.3290 - acc: 0.6571 - val_loss: 140.4636 - val_acc: 0.4480\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 149.6595 - acc: 0.7000 - val_loss: 139.1511 - val_acc: 0.4700\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 149.6093 - acc: 0.7071 - val_loss: nan - val_acc: 0.4800\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 141.2671 - acc: 0.7071 - val_loss: nan - val_acc: 0.4860\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 142.7150 - acc: 0.7071 - val_loss: nan - val_acc: 0.4900\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 143.5810 - acc: 0.7071 - val_loss: nan - val_acc: 0.4660\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan - acc: 0.4429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 24ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 29ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148bf2820>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=X_train[0].shape),\n",
    "    keras.layers.Dense(300, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(7, activation=keras.activations.relu)\n",
    "])\n",
    "\n",
    "# Compile model (based on the same parameters used with the espectral ConvGNN)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01), # Set optimizer as Adam with a learning rate of 0.01\n",
    "    loss=CategoricalCrossentropy(reduction=reduction_function), # Loss function to be used.\n",
    "    weighted_metrics=['acc'] # Metrics to be evaluated and weighted during training (Keras doc: https://keras.io/api/models/model_training_apis/)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10,  restore_best_weights=True), # Early stopping callback\n",
    "        TensorBoard(get_run_logdir('non_gnn'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 139.1920 - acc: 0.4940\n",
      "Loss: 139.19204711914062\n",
      "Accuracy: 0.49399998784065247\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {results[0]}')\n",
    "print(f'Accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0080289cbe72122e4cc1d387721a77267b793dcb0222027115d0fe70e838b1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('uoc-tfg-gnn': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
