{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFG: Alfonso Moure\n",
    "\n",
    "Este fichero contiene un borrador del proyecto TFG de Alfonso Moure, donde se exploran diferentes técnicas para el trabajo con redes neuronales gráficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando los módulos necesarios\n",
    "\n",
    "Como primer paso, se va a proceder a instalar los módulos necesarios para las pruebas:\n",
    "\n",
    "* [numpy](https://numpy.org/), para poder realizar las operaciones necesarias sobre los datos.\n",
    "* [TensorFlow](https://www.tensorflow.org/), como librería principal para ejecutar los distintos algoritmos de aprendizaje computacional a los que será necesario recurrir.\n",
    "* [Spektral](https://graphneural.network/), una cómoda librería y colección de sets de datos que permite trabajar de manera cómoda con redes neuronales gráficas.\n",
    "\n",
    "Una vez instalados, se procede a imporarlos. Aunque se incluye la descripción del fichero requierements.txt con el proyecto, se proceden a importar desde el notebook para aportar una mayor claridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.19.5)\n",
      "Requirement already satisfied: tensorflow in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: spektral in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: joblib in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (4.62.3)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.0.1)\n",
      "Requirement already satisfied: requests in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.26.0)\n",
      "Requirement already satisfied: lxml in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (4.6.4)\n",
      "Requirement already satisfied: scipy in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.7.2)\n",
      "Requirement already satisfied: pandas in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.3.4)\n",
      "Requirement already satisfied: networkx in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (2.6.3)\n",
      "Requirement already satisfied: numpy<1.20 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from spektral) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.37.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.13.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (12.0.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (4.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.42.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorflow>=2.1.0->spektral) (0.22.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->spektral) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pandas->spektral) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests->spektral) (1.26.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from scikit-learn->spektral) (3.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (57.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required modules\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import downloaded modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, se crea un fichero de configuración para Spektral en el directorio raíz del usuario, tal y como se indica en la configuración de dicho módulo. Se crea en la ruta `~/.spektral/config.json` y se guarda el siguiente contenido:\n",
    "\n",
    "```\n",
    "{\n",
    "        \"dataset_folder\": \"/Users/ghostmou/vscode-projects/uoc-tfg-gnn/spektraldata\"\n",
    "}\n",
    "```\n",
    "\n",
    "Esto indica a Spektral que se desea guardar la información descargada para los juegos de datos que van a ser usados en la ruta indicada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del juego de datos para las pruebas\n",
    "\n",
    "Como se indica en la memoria de proyecto, se hará uso del juego de datos conocido como CORA. Gracias a Spektral, es sencillo descargar este juego de datos y sus distintas estructuras ya preparadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cora dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghostmou/virtualenvs/uoc-tfg-gnn/lib/python3.9/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download CORA dataset and its different members\n",
    "dataset = spektral.datasets.citation.Citation(\n",
    "    'cora', \n",
    "    random_split=False, # split randomly: 20 nodes per class for training, 30 nodes \n",
    "        # per class for validation; or \"Planetoid\" (Yang et al. 2016)\n",
    "    normalize_x=False,  # normalize the features\n",
    "    dtype=np.float32 # numpy data type for the graph data\n",
    "    )\n",
    "dataset.graphs[0]\n",
    "\n",
    "# Also load a list of labels as names, justo to be able to use it\n",
    "label_names = ['Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el conjunto de datos descargado, podemos ver que el resumen nos muestra que se ha descargado un grafo con las siguientes características:\n",
    "\n",
    "* 2708 nodos o vértices forman el grafo.\n",
    "* 1433 atributos de nodo.\n",
    "* 0 atributos de relación, es decir, es un nodo cuyas aristas no contienen información.\n",
    "* 7 clases. En base a la definición del juego de datos, sabemos que los vértices se clasifican en dicho número de grupos. Sin embargo, como se explica en la memoria de proyecto, también es posible hacer uso de GNNs para clasificar grafos, por lo que Spektral nos permite trabajar con dos tipos de etiquetas: de nodo y de grafo.\n",
    "\n",
    "Por otro lado, el conjunto de datos recuperado ya viene dividido en tres grupos de muestras:\n",
    "\n",
    "* Muestras de entrenamiento, que aparecen marcadas mediante enmascaramiento con la estructura `mask_tr`.\n",
    "* Muestras de validación, que hacen lo propio mediante `mask_va`.\n",
    "* Muestras de prueba o test, enmascaradas con `mask_te`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 140\n",
      "Validation samples: 500\n",
      "Test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Training samples: {np.sum(dataset.mask_tr)}')\n",
    "print(f'Validation samples: {np.sum(dataset.mask_va)}')\n",
    "print(f'Test samples: {np.sum(dataset.mask_te)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación TensorBoard para seguimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder con la implementación de los ejemplos, se prepara un entorno basado en TensorBoard para poder visualizar y analizar la ejecución  y sus resultados de manera visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorBoard callback to be able to use it in all the code samples\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Prepare placement for the logs\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "def get_run_logdir(model_in_use):\n",
    "    import time\n",
    "    run_id = time.strftime(f'run_{model_in_use}_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de pruebas\n",
    "\n",
    "A continuación, se va a trabajar en la implementación de varios modelos diferentes de ConvGNN para explicar su funcionamiento:\n",
    "\n",
    "* ConvGNN espectral, con un ejemplo de clasificación de nodos.\n",
    "* ConvGNN espacial con paso de mensajes o MPNN, con un ejemplo de clasificación de nodos.\n",
    "\n",
    "Cada apartado irá rematado con un estudio de precisión. Todos los casos serán ejecutados mediante GridSearch para intentar encontrar el resultado más óptimo bajo las condiciones actuales. Además, se extraerá información gráfica mediante TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 1: ConvGNN espectral\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede verse que se cuenta con 140 muestras de entrenamiento, 500 de validación y 1000 de test.\n",
    "\n",
    "Dado que este enmascaramiento se lleva a cabo mediante datos binarios (verdadero o falso; incluido o excluido de cada subconjunto, respectivamente), es preciso transformar estos valores en pesos que puedan ser usados durante el proceso de aprendizaje: sabemos que las CNN espestrales no hacen uso de los features de nodos y vértices para su toma de decisiones.\n",
    "\n",
    "Para ello, se crea una función que convierte estas colecciones en una media de peso de los valores de los nodos.\n",
    "\n",
    "**ESTE BLOQUE REQUIERE REVISIÓN DESDE MIS NOTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighed_mask = [\n",
    "    mask.astype(np.float32) / np.count_nonzero(mask)\n",
    "    for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, cada vértice de cada colección de muestras tendrá asignado un peso igual al del resto de su conjunto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples weight: 0.0071428571827709675\n",
      "Validation samples weight: 0.0020000000949949026\n",
      "Test samples weight: 0.0010000001639127731\n"
     ]
    }
   ],
   "source": [
    "print(f'Training samples weight: {np.nanmean(np.where(weighed_mask[0] > 0, weighed_mask[0],np.nan), 0)}')\n",
    "print(f'Validation samples weight: {np.nanmean(np.where(weighed_mask[1] > 0, weighed_mask[1],np.nan), 0)}')\n",
    "print(f'Test samples weight: {np.nanmean(np.where(weighed_mask[2] > 0, weighed_mask[2],np.nan), 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparados los datos, se puede proceder a definir el modelo. Para ello, se hará uso del existente GCN procedente de Spektral (`spektral.models.gcn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 12:34:39.512287: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "from spektral.models.gcn import GCN\n",
    "\n",
    "# Import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Import loss function from Keras\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Set initial configuration\n",
    "learning_rate = 0.01\n",
    "reduction_function = 'sum'\n",
    "\n",
    "# Create model from Spektral\n",
    "model_gcn = GCN(n_labels=dataset.n_labels, n_input_channels=dataset.n_node_features)\n",
    "\n",
    "# Compile loaded model\n",
    "model_gcn.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate), # Set optimizer as Adam with a learning rate of 0.01\n",
    "    loss=CategoricalCrossentropy(reduction=reduction_function), # Loss function to be used.\n",
    "    weighted_metrics=['acc'] # Metrics to be evaluated and weighted during training (Keras doc: https://keras.io/api/models/model_training_apis/)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos el modelo creado y compilado, es posible proceder con su entrenamiento. Para ello, se empieza por crear los cargadores (*Loaders*) de Spektral para entrenamiento y validación, básicos para las tareas de entrenamiento. Dentro de Spektral, los *loaders* son usados para generar lotes de subgrafos para poder hacer sucesivas pasadas de entrenamiento en la red convolucional en uso. \n",
    "\n",
    "Gracias a que Spektral está diseñado para trabajar con Keras, la clase `Loader` incluye un método `load` que puede ser usado en para llamar al método `fit` del modelo.\n",
    "\n",
    "Puesto que el conjunto de datos incluye un solo grafo, es posible hacer uso del cargador `SingleLoader`, diseñado para trabajar con este tipo de estructuras de grafo único. Puede ser configurado mediante los siguientes parámetros pasados durante su inicialización:\n",
    "\n",
    "* `dataset`, que incluye, como puede deducirse, la estructura de datos.\n",
    "* `epochs`, con la cantidad de **epochs** que van a ser usados durante la fase de entrenamiento.\n",
    "* `shuffle`, para indicar si se desea barajar los contenidos del conjunto de datos tras cada epoch.\n",
    "* `sample_weights`, que podrá ser usado para indicar el peso de cada observación y que, en caso de ser usado en la inicialización, será devuelto en cada paso de entrenamiento. Esta es la estructura que hemos generado con anterioridad para cada subconjunto de entrenamiento, pruebas y validación en base a las estructuras binarias originales. Así, se usará un vector de pesos diferente según el cargador que estemos preparando.\n",
    "\n",
    "Puesto que el siguiente paso es llevar a cabo el entrenamiento del modelo, se prepararán los cargadores de los datos de entrenamiento y validación mediante `SingleLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data.loaders import SingleLoader\n",
    "loader_training = SingleLoader(dataset, sample_weights=weighed_mask[0])\n",
    "loader_validation = SingleLoader(dataset, sample_weights=weighed_mask[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los cargadores listos, es posible proceder a entrenar el modelo mediante la función `fit`. A modo de prueba, se hará con un total de `50` epochs. Además, se incorpora un callback de Keras, `EarlyStopping`, que permitirá detener el entrenamiento cuando el proceso detecte que no se está obteniendo una mejora sustancial.\n",
    "\n",
    "Como se mencionó más arriba, se incorpora también un callback `TensorBoard` para poder analizar las pruebas. Sus resultados serán accesibles mediante el siguiente comando de consola:\n",
    "\n",
    "```shell\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.2150 - acc: 0.0857 - val_loss: 4.3337 - val_acc: 0.1680\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4113 - acc: 0.2429 - val_loss: 2.5733 - val_acc: 0.2700\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6410 - acc: 0.3071 - val_loss: 1.9669 - val_acc: 0.2540\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7633 - acc: 0.3857 - val_loss: 1.9606 - val_acc: 0.2200\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6963 - acc: 0.3571 - val_loss: 1.7960 - val_acc: 0.2960\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4287 - acc: 0.5071 - val_loss: 1.9187 - val_acc: 0.3020\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4357 - acc: 0.4286 - val_loss: 1.8812 - val_acc: 0.3020\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3676 - acc: 0.5071 - val_loss: 1.7449 - val_acc: 0.3160\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9466 - acc: 0.4643 - val_loss: 1.6365 - val_acc: 0.3840\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2348 - acc: 0.5786 - val_loss: 1.6335 - val_acc: 0.3980\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4014 - acc: 0.5643 - val_loss: 1.6515 - val_acc: 0.3920\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3923 - acc: 0.4929 - val_loss: 1.6640 - val_acc: 0.4380\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2087 - acc: 0.6143 - val_loss: 1.6724 - val_acc: 0.4600\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8109 - acc: 0.5500 - val_loss: 1.7085 - val_acc: 0.4440\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4909 - acc: 0.6214 - val_loss: 1.6530 - val_acc: 0.5380\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0779 - acc: 0.6429 - val_loss: 1.5436 - val_acc: 0.5900\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9950 - acc: 0.7286 - val_loss: 1.4863 - val_acc: 0.6320\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9669 - acc: 0.7000 - val_loss: 1.4708 - val_acc: 0.6340\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8943 - acc: 0.7357 - val_loss: 1.4395 - val_acc: 0.6500\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9858 - acc: 0.7357 - val_loss: 1.4150 - val_acc: 0.6620\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9814 - acc: 0.6929 - val_loss: 1.4040 - val_acc: 0.6620\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8181 - acc: 0.7214 - val_loss: 1.3966 - val_acc: 0.6640\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8496 - acc: 0.7071 - val_loss: 1.3916 - val_acc: 0.6660\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8146 - acc: 0.7643 - val_loss: 1.3882 - val_acc: 0.6820\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7773 - acc: 0.7786 - val_loss: 1.3495 - val_acc: 0.6900\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9234 - acc: 0.7357 - val_loss: 1.3611 - val_acc: 0.6780\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6682 - acc: 0.7643 - val_loss: 1.3811 - val_acc: 0.6780\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7922 - acc: 0.7571 - val_loss: 1.4116 - val_acc: 0.6780\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7620 - acc: 0.7643 - val_loss: 1.4364 - val_acc: 0.6820\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7107 - acc: 0.8214 - val_loss: 1.4704 - val_acc: 0.6840\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6044 - acc: 0.8286 - val_loss: 1.5010 - val_acc: 0.6820\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6729 - acc: 0.8071 - val_loss: 1.5422 - val_acc: 0.6700\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5684 - acc: 0.8286 - val_loss: 1.5880 - val_acc: 0.6720\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4591 - acc: 0.8643 - val_loss: 1.6266 - val_acc: 0.6720\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6276 - acc: 0.7929 - val_loss: 1.6597 - val_acc: 0.6720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1469051c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model_gcn.fit(\n",
    "    loader_training.load(),\n",
    "    steps_per_epoch=loader_training.steps_per_epoch,\n",
    "    validation_data=loader_validation.load(),\n",
    "    validation_steps=loader_validation.steps_per_epoch,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10,  restore_best_weights=True), # Early stopping callback\n",
    "        TensorBoard(get_run_logdir('gcn_spectral'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho este entrenamiento, se puede proceder a evaluar su eficacia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3889 - acc: 0.6890\n",
      "Loss: 1.388916015625\n",
      "Accuracy: 0.6890002489089966\n"
     ]
    }
   ],
   "source": [
    "loader_test = SingleLoader(dataset, sample_weights=weighed_mask[2])\n",
    "results = model_gcn.evaluate(\n",
    "    loader_test.load(), \n",
    "    steps=loader_test.steps_per_epoch\n",
    ")\n",
    "print(f'Loss: {results[0]}')\n",
    "print(f'Accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 2: ConvGNN espacial mediante paso de mensajes: MPNN\n",
    "\n",
    "En el ejemplo anterior se ha basado el aprendizaje y la clasificación en la estructura espectral de los datos cargados, es decir, en la esutructura de la matriz de adyacencia. Sin embargo, tal y como se explica en la memoria de proyecto, esta aproximación puede ser pobre para escenarios donde las relaciones (aristas) entre entidades (vértices) del grafo tienen un significado o importancia diferente, o cuando el contexto de un nodo, construido mediante los atributos de sus vecinos, es importante para la clasificación.\n",
    "\n",
    "Para poder preparar este ejemplo, se hará uso de la clase `MessagePassing` de Spektral, que ofrece una API ya preparada para configurar la función de activación y personalizar el comportamiento para distintos juegos de datos. Así, será preciso personalizar:\n",
    "\n",
    "* Función para la construcción del mensaje pasado entre dos vértices vía la arista que los une. Es conocida como `message` dentro de la API de Spektral.\n",
    "* Selección de la función de agregación de los mensajes pasados desde cada arista a cada nodo: suma, media, etc. Aparece definida como `aggregate`.\n",
    "\n",
    "Puesto que las GNN basadas en paso de mensajes requieren sucesivas iteraciones que permitan propagar los mensajes a niveles cada vez más lejanos, la función `propagate` lo ejecuta y computa los atributos de cada nodo tras pasar los mensajes de todas las aristas del grafo y computar la correspondiente función de agregación.\n",
    "\n",
    "Con todo, se empieza creando la clase MPNNLayer como herencia `MessagePassing` para preparar la personalización de los citados métodos y definir la capa de paso de mensajes del modelo a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import MessagePassing\n",
    "\n",
    "# TODO Refactor this!\n",
    "\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, n_out, activation, **kwargs):\n",
    "        # Initialize message passing layer with the activation function chosen when creating the model\n",
    "        super().__init__(activation=activation, **kwargs)\n",
    "        self.n_out = n_out\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        n_in = input_shape[0][-1]\n",
    "        self.weights = self.add_weight(shape=(n_in, self.n_out))\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x, a = inputs\n",
    "\n",
    "        # Update node features based on inputs by multiplying node attributes by \n",
    "        # the weights stored during build.\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/linalg/matmul\n",
    "        x = tf.matmul(x, self.weights)\n",
    "\n",
    "        # Return propagation result\n",
    "        return self.propagate(x=x, a=a)\n",
    "\n",
    "    def message(self, x, **kwargs):\n",
    "        # We can access information from each side of the link between the nodes i and j: j <-- j\n",
    "        # edge indices: index_i, index_j attributes\n",
    "        # access edges: get_i, get_j methods\n",
    "\n",
    "        # Try to return neighbors' features\n",
    "        return self.get_j(x)\n",
    "        # Try to return node features\n",
    "        # return self.get_i(x)\n",
    "    \n",
    "    def aggregate(self, messages, **kwargs): \n",
    "        # We need to return the result of applying the aggregate function over the messages\n",
    "        # TODO Possible improvement: pass the aggregate function as an hyperparameter to the layer to test different solutions\n",
    "\n",
    "        # Try to use the mean as aggregate function. We use a scatter mean method for this experiment:\n",
    "        return spektral.layers.ops.scatter_mean(messages, self.index_i, self.n_nodes)\n",
    "\n",
    "    def update(self, embeddings, **kwargs):\n",
    "        return self.activation(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota para MOU**: me he quedado intentando construir una layer de MPNN en base a lo que leo aquí:\n",
    "\n",
    "https://graphneural.network/creating-layer/\n",
    "\n",
    "Estoy cansado y no me da para más, pero creo que tienes que crear el modelo con Keras y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPNNLayer(n_out=dataset.n_labels, n_labels=dataset.n_labels, n_input_channels=dataset.n_node_features, activation=tf.keras.activations.relu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 3: clasificación de nodos mediante CNN sin uso de estructura gráfica\n",
    "\n",
    "El primer paso será construir una estructura de datos que nos permita trabajar con un modelo que no esté diseñado para operar sobre grafos. Para ello, se extraerán las características de cada observación de los datos de origen y no se usarán sus enlaces. Con todo, el objetivo es medir el nivel de precisión a la hora de clasificar sin utilizar la estructura generado mediante las relaciones entre nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: X (140, 1433), y (140, 7), from a source of 140 samples\n",
      "Validation: X (500, 1433), y (500, 7), from a source of 500 samples\n",
      "Test: X (1000, 1433), y (1000, 7), from a source of 1000 samples\n"
     ]
    }
   ],
   "source": [
    "# Extract train, validation and test features and labels\n",
    "X_train = dataset[0].x[np.array(dataset.mask_tr)]\n",
    "y_train = dataset[0].y[np.array(dataset.mask_tr)]\n",
    "X_validation = dataset[0].x[np.array(dataset.mask_va)]\n",
    "y_validation = dataset[0].y[np.array(dataset.mask_va)]\n",
    "X_test = dataset[0].x[np.array(dataset.mask_te)]\n",
    "y_test = dataset[0].y[np.array(dataset.mask_te)]\n",
    "\n",
    "print(f'Training: X {X_train.shape}, y {y_train.shape}, from a source of {np.sum(dataset.mask_tr)} samples')\n",
    "print(f'Validation: X {X_validation.shape}, y {y_validation.shape}, from a source of {np.sum(dataset.mask_va)} samples')\n",
    "print(f'Test: X {X_test.shape}, y {y_test.shape}, from a source of {np.sum(dataset.mask_te)} samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - 1s 54ms/step - loss: 275.7899 - acc: 0.2214 - val_loss: 183.8702 - val_acc: 0.3520\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 180.6099 - acc: 0.5214 - val_loss: 162.0301 - val_acc: 0.3980\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 154.3290 - acc: 0.6571 - val_loss: 140.4636 - val_acc: 0.4480\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 149.6595 - acc: 0.7000 - val_loss: 139.1511 - val_acc: 0.4700\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 149.6093 - acc: 0.7071 - val_loss: nan - val_acc: 0.4800\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 141.2671 - acc: 0.7071 - val_loss: nan - val_acc: 0.4860\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 142.7150 - acc: 0.7071 - val_loss: nan - val_acc: 0.4900\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 143.5810 - acc: 0.7071 - val_loss: nan - val_acc: 0.4660\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan - acc: 0.4429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 24ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 20ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 16ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 29ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 18ms/step - loss: nan - acc: 0.1429 - val_loss: nan - val_acc: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148bf2820>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=X_train[0].shape),\n",
    "    keras.layers.Dense(300, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(7, activation=keras.activations.relu)\n",
    "])\n",
    "\n",
    "# Compile model (based on the same parameters used with the espectral ConvGNN)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01), # Set optimizer as Adam with a learning rate of 0.01\n",
    "    loss=CategoricalCrossentropy(reduction=reduction_function), # Loss function to be used.\n",
    "    weighted_metrics=['acc'] # Metrics to be evaluated and weighted during training (Keras doc: https://keras.io/api/models/model_training_apis/)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10,  restore_best_weights=True), # Early stopping callback\n",
    "        TensorBoard(get_run_logdir('non_gnn'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 139.1920 - acc: 0.4940\n",
      "Loss: 139.19204711914062\n",
      "Accuracy: 0.49399998784065247\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {results[0]}')\n",
    "print(f'Accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0080289cbe72122e4cc1d387721a77267b793dcb0222027115d0fe70e838b1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('uoc-tfg-gnn': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
